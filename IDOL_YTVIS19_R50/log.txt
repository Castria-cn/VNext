[11/28 16:35:39] detectron2 INFO: Rank of current process: 0. World size: 4
[11/28 16:35:40] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]
numpy                   1.26.1
detectron2              0.6 @/vhome/wangyaoning/VNext/detectron2
Compiler                GCC 11.4
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          535.54.03
CUDA_HOME               /share/apps/cuda/12.2
Pillow                  10.1.0
torchvision             0.16.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 16:35:40] detectron2 INFO: Command line arguments: Namespace(config_file='projects/IDOL/configs/ytvis19_r50.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:59279', opts=[])
[11/28 16:35:40] detectron2 INFO: Contents of args.config_file=projects/IDOL/configs/ytvis19_r50.yaml:
MODEL:
  META_ARCHITECTURE: "IDOL"
  WEIGHTS: "model_final.pth"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: True
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  IDOL:
    NUM_CLASSES: 40
    MULTI_CLS_ON: True
DATASETS:
  TRAIN: ("ytvis_2019_train",)
  TEST: ("ytvis_2019_val",)
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (8000,)
  MAX_ITER: 12000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  CHECKPOINT_PERIOD: 1000
INPUT:
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE:  10
  # MIN_SIZE_TRAIN_SAMPLING : ["range", "choice", "range_by_clip", "choice_by_clip"]
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  # RANDOM_FLIP : ["none", "horizontal", "flip_by_clip"]. "horizontal" is set by default.
  RANDOM_FLIP: "flip_by_clip"
  # AUGMENTATIONS: []
  # MIN_SIZE_TRAIN: (360, 480)
  MIN_SIZE_TRAIN: (320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 4
VERSION: 2
OUTPUT_DIR: ./IDOL_YTVIS19_R50

[11/28 16:35:40] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - ytvis_2019_val
  TRAIN:
  - ytvis_2019_train
FIND_UNUSED_PARAMETERS: true
GLOBAL:
  HACK: 1.0
INPUT:
  AUGMENTATIONS: []
  COCO_PRETRAIN: false
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  MIN_SIZE_TRAIN:
  - 320
  - 352
  - 392
  - 416
  - 448
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  MIN_SIZE_TRAIN_SAMPLING: choice_by_clip
  PRETRAIN_SAME_CROP: false
  RANDOM_FLIP: flip_by_clip
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE: 10
  SAMPLING_FRAME_SHUFFLE: false
  SAMPLING_INTERVAL: 1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  IDOL:
    ADD_NEW_SCORE: 0.2
    APPLY_CLS_THRES: 0.05
    BATCH_INFER_LEN: 10
    CLASS_WEIGHT: 2.0
    CLIP_STRIDE: 1
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INFERENCE_FW: true
    INFERENCE_SELECT_THRES: 0.1
    INFERENCE_TW: true
    L1_WEIGHT: 5.0
    MASK_STRIDE: 4
    MASK_WEIGHT: 2.0
    MATCH_STRIDE: 4
    MEMORY_LEN: 3
    MERGE_ON_CPU: true
    MULTI_CLS_ON: true
    NHEADS: 8
    NMS_PRE: 0.5
    NUM_CLASSES: 40
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    REID_WEIGHT: 2.0
    SET_COST_BOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TEMPORAL_SCORE_TYPE: mean
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: IDOL
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: model_final.pth
OUTPUT_DIR: ./IDOL_YTVIS19_R50
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 12000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/28 16:35:40] detectron2 INFO: Full config saved to ./IDOL_YTVIS19_R50/config.yaml
[11/28 16:35:40] d2.utils.env INFO: Using a generated random seed 43934055
[11/28 16:35:43] d2.engine.defaults INFO: Model:
IDOL(
  (detr): CondInst_segm(
    (detr): DeformableDETR(
      (transformer): DeformableTransformer(
        (encoder): DeformableTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (decoder): DeformableTransformerDecoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerDecoderLayer(
              (cross_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (dropout2): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout4): Dropout(p=0.1, inplace=False)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (bbox_embed): ModuleList(
            (0-5): 6 x MLP(
              (layers): ModuleList(
                (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
                (2): Linear(in_features=256, out_features=4, bias=True)
              )
            )
          )
        )
        (reference_points): Linear(in_features=256, out_features=2, bias=True)
      )
      (class_embed): ModuleList(
        (0-5): 6 x Linear(in_features=256, out_features=40, bias=True)
      )
      (bbox_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (query_embed): Embedding(300, 512)
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (3): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (backbone): Joiner(
        (0): MaskedBackbone(
          (backbone): ResNet(
            (stem): BasicStem(
              (conv1): Conv2d(
                3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
            )
            (res2): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv1): Conv2d(
                  64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
            )
            (res3): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv1): Conv2d(
                  256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
            )
            (res4): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
                (conv1): Conv2d(
                  512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (4): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (5): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
            )
            (res5): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
                (conv1): Conv2d(
                  1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
            )
          )
        )
        (1): PositionEmbeddingSine()
      )
    )
    (controller): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=169, bias=True)
      )
    )
    (mask_head): MaskHeadSmallConv(
      (lay1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay2): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dcn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (reid_embed_head): MLP(
      (layers): ModuleList(
        (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[11/28 16:36:00] d2.data.common INFO: Serializing 2238 elements to byte tensors and concatenating them all ...
[11/28 16:36:01] d2.data.common INFO: Serialized dataset takes 150.26 MiB
[11/28 16:36:02] fvcore.common.checkpoint INFO: [Checkpointer] Loading from model_final.pth ...
[11/28 16:36:03] d2.engine.train_loop INFO: Starting Training from iteration 0
[11/28 16:36:15] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/vhome/wangyaoning/VNext/detectron2/engine/train_loop.py", line 153, in train
    self.run_step()
  File "/vhome/wangyaoning/VNext/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/vhome/wangyaoning/VNext/detectron2/engine/train_loop.py", line 279, in run_step
    loss_dict = self.model(data)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/idol.py", line 229, in forward
    output, loss_dict = self.detr(images, det_targets,ref_targets, self.criterion, train=True)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/models/segmentation_condInst.py", line 214, in forward
    contrast_items = select_pos_neg(inter_references_ref[-1], matched_ids, ref_targets,det_targets, self.reid_embed_head, hs[-1], hs_ref[-1], ref_cls)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/models/pos_neg_select.py", line 34, in select_pos_neg
    logger.log_id(f'ref_box_bz shape={ref_box_bz.shape}', 1)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/util/ot_logger.py", line 17, in log_id
    with open(self.log_file, 'a') as f:
FileNotFoundError: [Errno 2] No such file or directory: '~/VNext/ot_log.txt'
[11/28 16:36:15] d2.engine.hooks INFO: Total training time: 0:00:11 (0:00:00 on hooks)
[11/28 16:36:15] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 16036M
[11/28 16:40:48] detectron2 INFO: Rank of current process: 0. World size: 4
[11/28 16:40:48] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]
numpy                   1.26.1
detectron2              0.6 @/vhome/wangyaoning/VNext/detectron2
Compiler                GCC 11.4
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          535.54.03
CUDA_HOME               /share/apps/cuda/12.2
Pillow                  10.1.0
torchvision             0.16.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 16:40:48] detectron2 INFO: Command line arguments: Namespace(config_file='projects/IDOL/configs/ytvis19_r50.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:59279', opts=[])
[11/28 16:40:48] detectron2 INFO: Contents of args.config_file=projects/IDOL/configs/ytvis19_r50.yaml:
MODEL:
  META_ARCHITECTURE: "IDOL"
  WEIGHTS: "model_final.pth"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: True
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  IDOL:
    NUM_CLASSES: 40
    MULTI_CLS_ON: True
DATASETS:
  TRAIN: ("ytvis_2019_train",)
  TEST: ("ytvis_2019_val",)
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (8000,)
  MAX_ITER: 12000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  CHECKPOINT_PERIOD: 1000
INPUT:
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE:  10
  # MIN_SIZE_TRAIN_SAMPLING : ["range", "choice", "range_by_clip", "choice_by_clip"]
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  # RANDOM_FLIP : ["none", "horizontal", "flip_by_clip"]. "horizontal" is set by default.
  RANDOM_FLIP: "flip_by_clip"
  # AUGMENTATIONS: []
  # MIN_SIZE_TRAIN: (360, 480)
  MIN_SIZE_TRAIN: (320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 4
VERSION: 2
OUTPUT_DIR: ./IDOL_YTVIS19_R50

[11/28 16:40:48] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - ytvis_2019_val
  TRAIN:
  - ytvis_2019_train
FIND_UNUSED_PARAMETERS: true
GLOBAL:
  HACK: 1.0
INPUT:
  AUGMENTATIONS: []
  COCO_PRETRAIN: false
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  MIN_SIZE_TRAIN:
  - 320
  - 352
  - 392
  - 416
  - 448
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  MIN_SIZE_TRAIN_SAMPLING: choice_by_clip
  PRETRAIN_SAME_CROP: false
  RANDOM_FLIP: flip_by_clip
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE: 10
  SAMPLING_FRAME_SHUFFLE: false
  SAMPLING_INTERVAL: 1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  IDOL:
    ADD_NEW_SCORE: 0.2
    APPLY_CLS_THRES: 0.05
    BATCH_INFER_LEN: 10
    CLASS_WEIGHT: 2.0
    CLIP_STRIDE: 1
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INFERENCE_FW: true
    INFERENCE_SELECT_THRES: 0.1
    INFERENCE_TW: true
    L1_WEIGHT: 5.0
    MASK_STRIDE: 4
    MASK_WEIGHT: 2.0
    MATCH_STRIDE: 4
    MEMORY_LEN: 3
    MERGE_ON_CPU: true
    MULTI_CLS_ON: true
    NHEADS: 8
    NMS_PRE: 0.5
    NUM_CLASSES: 40
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    REID_WEIGHT: 2.0
    SET_COST_BOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TEMPORAL_SCORE_TYPE: mean
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: IDOL
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: model_final.pth
OUTPUT_DIR: ./IDOL_YTVIS19_R50
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 12000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/28 16:40:48] detectron2 INFO: Full config saved to ./IDOL_YTVIS19_R50/config.yaml
[11/28 16:40:48] d2.utils.env INFO: Using a generated random seed 52550136
[11/28 16:40:52] d2.engine.defaults INFO: Model:
IDOL(
  (detr): CondInst_segm(
    (detr): DeformableDETR(
      (transformer): DeformableTransformer(
        (encoder): DeformableTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (decoder): DeformableTransformerDecoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerDecoderLayer(
              (cross_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (dropout2): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout4): Dropout(p=0.1, inplace=False)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (bbox_embed): ModuleList(
            (0-5): 6 x MLP(
              (layers): ModuleList(
                (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
                (2): Linear(in_features=256, out_features=4, bias=True)
              )
            )
          )
        )
        (reference_points): Linear(in_features=256, out_features=2, bias=True)
      )
      (class_embed): ModuleList(
        (0-5): 6 x Linear(in_features=256, out_features=40, bias=True)
      )
      (bbox_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (query_embed): Embedding(300, 512)
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (3): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (backbone): Joiner(
        (0): MaskedBackbone(
          (backbone): ResNet(
            (stem): BasicStem(
              (conv1): Conv2d(
                3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
            )
            (res2): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv1): Conv2d(
                  64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
            )
            (res3): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv1): Conv2d(
                  256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
            )
            (res4): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
                (conv1): Conv2d(
                  512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (4): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (5): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
            )
            (res5): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
                (conv1): Conv2d(
                  1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
            )
          )
        )
        (1): PositionEmbeddingSine()
      )
    )
    (controller): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=169, bias=True)
      )
    )
    (mask_head): MaskHeadSmallConv(
      (lay1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay2): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dcn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (reid_embed_head): MLP(
      (layers): ModuleList(
        (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[11/28 16:41:06] d2.data.common INFO: Serializing 2238 elements to byte tensors and concatenating them all ...
[11/28 16:41:06] d2.data.common INFO: Serialized dataset takes 150.26 MiB
[11/28 16:41:06] fvcore.common.checkpoint INFO: [Checkpointer] Loading from model_final.pth ...
[11/28 16:41:07] d2.engine.train_loop INFO: Starting Training from iteration 0
[11/28 16:41:35] d2.utils.events INFO:  eta: 2:48:36  iter: 19  total_loss: 8.966  loss_ce: 0.2951  loss_bbox: 0.2099  loss_giou: 0.1791  loss_mask: 0.03001  loss_dice: 0.4157  loss_reid: 2.011  loss_reid_aux: 0.08543  loss_ce_0: 0.3377  loss_bbox_0: 0.2985  loss_giou_0: 0.2446  loss_mask_0: 0.03137  loss_dice_0: 0.4041  loss_ce_1: 0.2974  loss_bbox_1: 0.2204  loss_giou_1: 0.1931  loss_mask_1: 0.03075  loss_dice_1: 0.4131  loss_ce_2: 0.2818  loss_bbox_2: 0.2053  loss_giou_2: 0.1801  loss_mask_2: 0.0309  loss_dice_2: 0.4196  loss_ce_3: 0.2757  loss_bbox_3: 0.2132  loss_giou_3: 0.181  loss_mask_3: 0.03091  loss_dice_3: 0.4119  loss_ce_4: 0.2881  loss_bbox_4: 0.2099  loss_giou_4: 0.1779  loss_mask_4: 0.03061  loss_dice_4: 0.4123  time: 0.8416  data_time: 0.5876  lr: 0.0001  max_mem: 17554M
[11/28 16:41:52] d2.utils.events INFO:  eta: 2:47:15  iter: 39  total_loss: 8.936  loss_ce: 0.315  loss_bbox: 0.2088  loss_giou: 0.1631  loss_mask: 0.03681  loss_dice: 0.3967  loss_reid: 1.883  loss_reid_aux: 0.08342  loss_ce_0: 0.3379  loss_bbox_0: 0.2972  loss_giou_0: 0.2383  loss_mask_0: 0.04012  loss_dice_0: 0.3912  loss_ce_1: 0.3059  loss_bbox_1: 0.2186  loss_giou_1: 0.1678  loss_mask_1: 0.03743  loss_dice_1: 0.3901  loss_ce_2: 0.3121  loss_bbox_2: 0.209  loss_giou_2: 0.1613  loss_mask_2: 0.0382  loss_dice_2: 0.3929  loss_ce_3: 0.3013  loss_bbox_3: 0.211  loss_giou_3: 0.1613  loss_mask_3: 0.03915  loss_dice_3: 0.3852  loss_ce_4: 0.3068  loss_bbox_4: 0.2086  loss_giou_4: 0.1631  loss_mask_4: 0.03818  loss_dice_4: 0.3894  time: 0.8327  data_time: 0.0208  lr: 0.0001  max_mem: 17554M
[11/28 17:32:52] detectron2 INFO: Rank of current process: 0. World size: 4
[11/28 17:32:53] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]
numpy                   1.26.1
detectron2              0.6 @/vhome/wangyaoning/VNext/detectron2
Compiler                GCC 11.4
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          535.54.03
CUDA_HOME               /share/apps/cuda/12.2
Pillow                  10.1.0
torchvision             0.16.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 17:32:53] detectron2 INFO: Command line arguments: Namespace(config_file='projects/IDOL/configs/ytvis19_r50.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:59279', opts=[])
[11/28 17:32:53] detectron2 INFO: Contents of args.config_file=projects/IDOL/configs/ytvis19_r50.yaml:
MODEL:
  META_ARCHITECTURE: "IDOL"
  WEIGHTS: "model_final.pth"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: True
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  IDOL:
    NUM_CLASSES: 40
    MULTI_CLS_ON: True
DATASETS:
  TRAIN: ("ytvis_2019_train",)
  TEST: ("ytvis_2019_val",)
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (8000,)
  MAX_ITER: 12000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  CHECKPOINT_PERIOD: 1000
INPUT:
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE:  10
  # MIN_SIZE_TRAIN_SAMPLING : ["range", "choice", "range_by_clip", "choice_by_clip"]
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  # RANDOM_FLIP : ["none", "horizontal", "flip_by_clip"]. "horizontal" is set by default.
  RANDOM_FLIP: "flip_by_clip"
  # AUGMENTATIONS: []
  # MIN_SIZE_TRAIN: (360, 480)
  MIN_SIZE_TRAIN: (320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 4
VERSION: 2
OUTPUT_DIR: ./IDOL_YTVIS19_R50

[11/28 17:32:53] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - ytvis_2019_val
  TRAIN:
  - ytvis_2019_train
FIND_UNUSED_PARAMETERS: true
GLOBAL:
  HACK: 1.0
INPUT:
  AUGMENTATIONS: []
  COCO_PRETRAIN: false
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  MIN_SIZE_TRAIN:
  - 320
  - 352
  - 392
  - 416
  - 448
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  MIN_SIZE_TRAIN_SAMPLING: choice_by_clip
  PRETRAIN_SAME_CROP: false
  RANDOM_FLIP: flip_by_clip
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE: 10
  SAMPLING_FRAME_SHUFFLE: false
  SAMPLING_INTERVAL: 1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  IDOL:
    ADD_NEW_SCORE: 0.2
    APPLY_CLS_THRES: 0.05
    BATCH_INFER_LEN: 10
    CLASS_WEIGHT: 2.0
    CLIP_STRIDE: 1
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INFERENCE_FW: true
    INFERENCE_SELECT_THRES: 0.1
    INFERENCE_TW: true
    L1_WEIGHT: 5.0
    MASK_STRIDE: 4
    MASK_WEIGHT: 2.0
    MATCH_STRIDE: 4
    MEMORY_LEN: 3
    MERGE_ON_CPU: true
    MULTI_CLS_ON: true
    NHEADS: 8
    NMS_PRE: 0.5
    NUM_CLASSES: 40
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    REID_WEIGHT: 2.0
    SET_COST_BOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TEMPORAL_SCORE_TYPE: mean
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: IDOL
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: model_final.pth
OUTPUT_DIR: ./IDOL_YTVIS19_R50
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 12000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/28 17:32:53] detectron2 INFO: Full config saved to ./IDOL_YTVIS19_R50/config.yaml
[11/28 17:32:53] d2.utils.env INFO: Using a generated random seed 56645573
[11/28 17:32:56] d2.engine.defaults INFO: Model:
IDOL(
  (detr): CondInst_segm(
    (detr): DeformableDETR(
      (transformer): DeformableTransformer(
        (encoder): DeformableTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (decoder): DeformableTransformerDecoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerDecoderLayer(
              (cross_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (dropout2): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout4): Dropout(p=0.1, inplace=False)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (bbox_embed): ModuleList(
            (0-5): 6 x MLP(
              (layers): ModuleList(
                (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
                (2): Linear(in_features=256, out_features=4, bias=True)
              )
            )
          )
        )
        (reference_points): Linear(in_features=256, out_features=2, bias=True)
      )
      (class_embed): ModuleList(
        (0-5): 6 x Linear(in_features=256, out_features=40, bias=True)
      )
      (bbox_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (query_embed): Embedding(300, 512)
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (3): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (backbone): Joiner(
        (0): MaskedBackbone(
          (backbone): ResNet(
            (stem): BasicStem(
              (conv1): Conv2d(
                3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
            )
            (res2): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv1): Conv2d(
                  64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
            )
            (res3): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv1): Conv2d(
                  256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
            )
            (res4): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
                (conv1): Conv2d(
                  512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (4): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (5): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
            )
            (res5): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
                (conv1): Conv2d(
                  1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
            )
          )
        )
        (1): PositionEmbeddingSine()
      )
    )
    (controller): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=169, bias=True)
      )
    )
    (mask_head): MaskHeadSmallConv(
      (lay1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay2): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dcn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (reid_embed_head): MLP(
      (layers): ModuleList(
        (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[11/28 17:33:10] d2.data.common INFO: Serializing 2238 elements to byte tensors and concatenating them all ...
[11/28 17:33:10] d2.data.common INFO: Serialized dataset takes 150.26 MiB
[11/28 17:33:11] fvcore.common.checkpoint INFO: [Checkpointer] Loading from model_final.pth ...
[11/28 17:33:11] d2.engine.train_loop INFO: Starting Training from iteration 0
[11/28 17:33:40] d2.utils.events INFO:  eta: 2:54:27  iter: 19  total_loss: 8.392  loss_ce: 0.2612  loss_bbox: 0.1901  loss_giou: 0.1592  loss_mask: 0.02858  loss_dice: 0.3503  loss_reid: 1.349  loss_reid_aux: 0.08468  loss_ce_0: 0.3207  loss_bbox_0: 0.2701  loss_giou_0: 0.2379  loss_mask_0: 0.0297  loss_dice_0: 0.3513  loss_ce_1: 0.2778  loss_bbox_1: 0.1986  loss_giou_1: 0.1749  loss_mask_1: 0.02808  loss_dice_1: 0.3426  loss_ce_2: 0.2636  loss_bbox_2: 0.188  loss_giou_2: 0.1634  loss_mask_2: 0.02814  loss_dice_2: 0.3451  loss_ce_3: 0.2447  loss_bbox_3: 0.1912  loss_giou_3: 0.1634  loss_mask_3: 0.02855  loss_dice_3: 0.3539  loss_ce_4: 0.2486  loss_bbox_4: 0.1898  loss_giou_4: 0.1598  loss_mask_4: 0.02813  loss_dice_4: 0.353  time: 0.8684  data_time: 0.5611  lr: 0.0001  max_mem: 17145M
[11/28 17:33:57] d2.utils.events INFO:  eta: 2:52:32  iter: 39  total_loss: 9.137  loss_ce: 0.3306  loss_bbox: 0.2064  loss_giou: 0.1568  loss_mask: 0.03861  loss_dice: 0.3859  loss_reid: 2.123  loss_reid_aux: 0.1023  loss_ce_0: 0.3872  loss_bbox_0: 0.3021  loss_giou_0: 0.2288  loss_mask_0: 0.04078  loss_dice_0: 0.4042  loss_ce_1: 0.3415  loss_bbox_1: 0.2228  loss_giou_1: 0.1695  loss_mask_1: 0.04052  loss_dice_1: 0.3911  loss_ce_2: 0.3348  loss_bbox_2: 0.2127  loss_giou_2: 0.1583  loss_mask_2: 0.03953  loss_dice_2: 0.3868  loss_ce_3: 0.3182  loss_bbox_3: 0.2063  loss_giou_3: 0.1581  loss_mask_3: 0.04028  loss_dice_3: 0.3808  loss_ce_4: 0.3293  loss_bbox_4: 0.2079  loss_giou_4: 0.1574  loss_mask_4: 0.0394  loss_dice_4: 0.3835  time: 0.8625  data_time: 0.0265  lr: 0.0001  max_mem: 17145M
[11/28 17:34:13] d2.utils.events INFO:  eta: 2:49:53  iter: 59  total_loss: 8.986  loss_ce: 0.3208  loss_bbox: 0.2104  loss_giou: 0.1773  loss_mask: 0.03937  loss_dice: 0.4159  loss_reid: 2.16  loss_reid_aux: 0.1056  loss_ce_0: 0.3465  loss_bbox_0: 0.3065  loss_giou_0: 0.2678  loss_mask_0: 0.04044  loss_dice_0: 0.42  loss_ce_1: 0.3182  loss_bbox_1: 0.2273  loss_giou_1: 0.1887  loss_mask_1: 0.04047  loss_dice_1: 0.4235  loss_ce_2: 0.3105  loss_bbox_2: 0.2159  loss_giou_2: 0.1788  loss_mask_2: 0.03941  loss_dice_2: 0.4213  loss_ce_3: 0.3037  loss_bbox_3: 0.2143  loss_giou_3: 0.1768  loss_mask_3: 0.03972  loss_dice_3: 0.4137  loss_ce_4: 0.3117  loss_bbox_4: 0.213  loss_giou_4: 0.179  loss_mask_4: 0.0396  loss_dice_4: 0.4168  time: 0.8489  data_time: 0.0253  lr: 0.0001  max_mem: 17145M
[11/28 17:34:30] d2.utils.events INFO:  eta: 2:49:05  iter: 79  total_loss: 9.295  loss_ce: 0.3025  loss_bbox: 0.1934  loss_giou: 0.1751  loss_mask: 0.03403  loss_dice: 0.4187  loss_reid: 1.867  loss_reid_aux: 0.09619  loss_ce_0: 0.3387  loss_bbox_0: 0.2928  loss_giou_0: 0.2505  loss_mask_0: 0.03603  loss_dice_0: 0.4098  loss_ce_1: 0.3044  loss_bbox_1: 0.2069  loss_giou_1: 0.1901  loss_mask_1: 0.0343  loss_dice_1: 0.4105  loss_ce_2: 0.2951  loss_bbox_2: 0.1937  loss_giou_2: 0.1809  loss_mask_2: 0.03304  loss_dice_2: 0.4321  loss_ce_3: 0.283  loss_bbox_3: 0.1934  loss_giou_3: 0.1781  loss_mask_3: 0.03409  loss_dice_3: 0.433  loss_ce_4: 0.2947  loss_bbox_4: 0.1941  loss_giou_4: 0.1768  loss_mask_4: 0.03408  loss_dice_4: 0.411  time: 0.8463  data_time: 0.0208  lr: 0.0001  max_mem: 17145M
[11/28 17:34:47] d2.utils.events INFO:  eta: 2:48:55  iter: 99  total_loss: 9.475  loss_ce: 0.2954  loss_bbox: 0.2053  loss_giou: 0.1692  loss_mask: 0.03797  loss_dice: 0.4067  loss_reid: 2.298  loss_reid_aux: 0.09025  loss_ce_0: 0.3471  loss_bbox_0: 0.2868  loss_giou_0: 0.2382  loss_mask_0: 0.04032  loss_dice_0: 0.4038  loss_ce_1: 0.3065  loss_bbox_1: 0.2193  loss_giou_1: 0.1876  loss_mask_1: 0.03896  loss_dice_1: 0.4085  loss_ce_2: 0.2946  loss_bbox_2: 0.2142  loss_giou_2: 0.1727  loss_mask_2: 0.0383  loss_dice_2: 0.402  loss_ce_3: 0.2834  loss_bbox_3: 0.2129  loss_giou_3: 0.1733  loss_mask_3: 0.03778  loss_dice_3: 0.4047  loss_ce_4: 0.2877  loss_bbox_4: 0.2088  loss_giou_4: 0.1743  loss_mask_4: 0.03722  loss_dice_4: 0.4042  time: 0.8468  data_time: 0.0233  lr: 0.0001  max_mem: 17488M
[11/28 17:35:04] d2.utils.events INFO:  eta: 2:48:40  iter: 119  total_loss: 9.379  loss_ce: 0.327  loss_bbox: 0.201  loss_giou: 0.1633  loss_mask: 0.03985  loss_dice: 0.4296  loss_reid: 2.154  loss_reid_aux: 0.09201  loss_ce_0: 0.3603  loss_bbox_0: 0.2803  loss_giou_0: 0.237  loss_mask_0: 0.04044  loss_dice_0: 0.4339  loss_ce_1: 0.3358  loss_bbox_1: 0.2108  loss_giou_1: 0.1678  loss_mask_1: 0.03938  loss_dice_1: 0.4214  loss_ce_2: 0.3271  loss_bbox_2: 0.2051  loss_giou_2: 0.1632  loss_mask_2: 0.0383  loss_dice_2: 0.4212  loss_ce_3: 0.3212  loss_bbox_3: 0.2028  loss_giou_3: 0.1634  loss_mask_3: 0.03815  loss_dice_3: 0.4336  loss_ce_4: 0.3256  loss_bbox_4: 0.2011  loss_giou_4: 0.1628  loss_mask_4: 0.03869  loss_dice_4: 0.4241  time: 0.8475  data_time: 0.0228  lr: 0.0001  max_mem: 17488M
[11/28 17:35:51] detectron2 INFO: Rank of current process: 0. World size: 4
[11/28 17:35:51] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]
numpy                   1.26.1
detectron2              0.6 @/vhome/wangyaoning/VNext/detectron2
Compiler                GCC 11.4
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          535.54.03
CUDA_HOME               /share/apps/cuda/12.2
Pillow                  10.1.0
torchvision             0.16.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 17:35:51] detectron2 INFO: Command line arguments: Namespace(config_file='projects/IDOL/configs/ytvis19_r50.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:59279', opts=[])
[11/28 17:35:51] detectron2 INFO: Contents of args.config_file=projects/IDOL/configs/ytvis19_r50.yaml:
MODEL:
  META_ARCHITECTURE: "IDOL"
  WEIGHTS: "model_final.pth"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: True
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  IDOL:
    NUM_CLASSES: 40
    MULTI_CLS_ON: True
DATASETS:
  TRAIN: ("ytvis_2019_train",)
  TEST: ("ytvis_2019_val",)
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (8000,)
  MAX_ITER: 12000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  CHECKPOINT_PERIOD: 1000
INPUT:
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE:  10
  # MIN_SIZE_TRAIN_SAMPLING : ["range", "choice", "range_by_clip", "choice_by_clip"]
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  # RANDOM_FLIP : ["none", "horizontal", "flip_by_clip"]. "horizontal" is set by default.
  RANDOM_FLIP: "flip_by_clip"
  # AUGMENTATIONS: []
  # MIN_SIZE_TRAIN: (360, 480)
  MIN_SIZE_TRAIN: (320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 4
VERSION: 2
OUTPUT_DIR: ./IDOL_YTVIS19_R50

[11/28 17:35:51] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - ytvis_2019_val
  TRAIN:
  - ytvis_2019_train
FIND_UNUSED_PARAMETERS: true
GLOBAL:
  HACK: 1.0
INPUT:
  AUGMENTATIONS: []
  COCO_PRETRAIN: false
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  MIN_SIZE_TRAIN:
  - 320
  - 352
  - 392
  - 416
  - 448
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  MIN_SIZE_TRAIN_SAMPLING: choice_by_clip
  PRETRAIN_SAME_CROP: false
  RANDOM_FLIP: flip_by_clip
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE: 10
  SAMPLING_FRAME_SHUFFLE: false
  SAMPLING_INTERVAL: 1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  IDOL:
    ADD_NEW_SCORE: 0.2
    APPLY_CLS_THRES: 0.05
    BATCH_INFER_LEN: 10
    CLASS_WEIGHT: 2.0
    CLIP_STRIDE: 1
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INFERENCE_FW: true
    INFERENCE_SELECT_THRES: 0.1
    INFERENCE_TW: true
    L1_WEIGHT: 5.0
    MASK_STRIDE: 4
    MASK_WEIGHT: 2.0
    MATCH_STRIDE: 4
    MEMORY_LEN: 3
    MERGE_ON_CPU: true
    MULTI_CLS_ON: true
    NHEADS: 8
    NMS_PRE: 0.5
    NUM_CLASSES: 40
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    REID_WEIGHT: 2.0
    SET_COST_BOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TEMPORAL_SCORE_TYPE: mean
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: IDOL
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: model_final.pth
OUTPUT_DIR: ./IDOL_YTVIS19_R50
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 12000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/28 17:35:51] detectron2 INFO: Full config saved to ./IDOL_YTVIS19_R50/config.yaml
[11/28 17:35:52] d2.utils.env INFO: Using a generated random seed 55584504
[11/28 17:35:55] d2.engine.defaults INFO: Model:
IDOL(
  (detr): CondInst_segm(
    (detr): DeformableDETR(
      (transformer): DeformableTransformer(
        (encoder): DeformableTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (decoder): DeformableTransformerDecoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerDecoderLayer(
              (cross_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (dropout2): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout4): Dropout(p=0.1, inplace=False)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (bbox_embed): ModuleList(
            (0-5): 6 x MLP(
              (layers): ModuleList(
                (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
                (2): Linear(in_features=256, out_features=4, bias=True)
              )
            )
          )
        )
        (reference_points): Linear(in_features=256, out_features=2, bias=True)
      )
      (class_embed): ModuleList(
        (0-5): 6 x Linear(in_features=256, out_features=40, bias=True)
      )
      (bbox_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (query_embed): Embedding(300, 512)
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (3): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (backbone): Joiner(
        (0): MaskedBackbone(
          (backbone): ResNet(
            (stem): BasicStem(
              (conv1): Conv2d(
                3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
            )
            (res2): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv1): Conv2d(
                  64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
            )
            (res3): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv1): Conv2d(
                  256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
            )
            (res4): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
                (conv1): Conv2d(
                  512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (4): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (5): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
            )
            (res5): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
                (conv1): Conv2d(
                  1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
            )
          )
        )
        (1): PositionEmbeddingSine()
      )
    )
    (controller): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=169, bias=True)
      )
    )
    (mask_head): MaskHeadSmallConv(
      (lay1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay2): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dcn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (reid_embed_head): MLP(
      (layers): ModuleList(
        (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[11/28 17:36:09] d2.data.common INFO: Serializing 2238 elements to byte tensors and concatenating them all ...
[11/28 17:36:09] d2.data.common INFO: Serialized dataset takes 150.26 MiB
[11/28 17:36:10] fvcore.common.checkpoint INFO: [Checkpointer] Loading from model_final.pth ...
[11/28 17:36:10] d2.engine.train_loop INFO: Starting Training from iteration 0
[11/28 17:36:22] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/vhome/wangyaoning/VNext/detectron2/engine/train_loop.py", line 153, in train
    self.run_step()
  File "/vhome/wangyaoning/VNext/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/vhome/wangyaoning/VNext/detectron2/engine/train_loop.py", line 279, in run_step
    loss_dict = self.model(data)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/idol.py", line 229, in forward
    output, loss_dict = self.detr(images, det_targets,ref_targets, self.criterion, train=True)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/models/segmentation_condInst.py", line 214, in forward
    contrast_items = select_pos_neg(inter_references_ref[-1], matched_ids, ref_targets,det_targets, self.reid_embed_head, hs[-1], hs_ref[-1], ref_cls)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/models/pos_neg_select.py", line 42, in select_pos_neg
    logger.log_id(f'positive shape: {pos_idx.shape}, negative shape: {neg_idx.shape}', 5)
AttributeError: 'list' object has no attribute 'shape'
[11/28 17:36:22] d2.engine.hooks INFO: Total training time: 0:00:11 (0:00:00 on hooks)
[11/28 17:36:22] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 12340M
[11/28 17:37:51] detectron2 INFO: Rank of current process: 0. World size: 4
[11/28 17:37:52] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]
numpy                   1.26.1
detectron2              0.6 @/vhome/wangyaoning/VNext/detectron2
Compiler                GCC 11.4
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          535.54.03
CUDA_HOME               /share/apps/cuda/12.2
Pillow                  10.1.0
torchvision             0.16.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 17:37:52] detectron2 INFO: Command line arguments: Namespace(config_file='projects/IDOL/configs/ytvis19_r50.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:59279', opts=[])
[11/28 17:37:52] detectron2 INFO: Contents of args.config_file=projects/IDOL/configs/ytvis19_r50.yaml:
MODEL:
  META_ARCHITECTURE: "IDOL"
  WEIGHTS: "model_final.pth"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: True
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  IDOL:
    NUM_CLASSES: 40
    MULTI_CLS_ON: True
DATASETS:
  TRAIN: ("ytvis_2019_train",)
  TEST: ("ytvis_2019_val",)
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (8000,)
  MAX_ITER: 12000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  CHECKPOINT_PERIOD: 1000
INPUT:
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE:  10
  # MIN_SIZE_TRAIN_SAMPLING : ["range", "choice", "range_by_clip", "choice_by_clip"]
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  # RANDOM_FLIP : ["none", "horizontal", "flip_by_clip"]. "horizontal" is set by default.
  RANDOM_FLIP: "flip_by_clip"
  # AUGMENTATIONS: []
  # MIN_SIZE_TRAIN: (360, 480)
  MIN_SIZE_TRAIN: (320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 4
VERSION: 2
OUTPUT_DIR: ./IDOL_YTVIS19_R50

[11/28 17:37:52] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - ytvis_2019_val
  TRAIN:
  - ytvis_2019_train
FIND_UNUSED_PARAMETERS: true
GLOBAL:
  HACK: 1.0
INPUT:
  AUGMENTATIONS: []
  COCO_PRETRAIN: false
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  MIN_SIZE_TRAIN:
  - 320
  - 352
  - 392
  - 416
  - 448
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  MIN_SIZE_TRAIN_SAMPLING: choice_by_clip
  PRETRAIN_SAME_CROP: false
  RANDOM_FLIP: flip_by_clip
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE: 10
  SAMPLING_FRAME_SHUFFLE: false
  SAMPLING_INTERVAL: 1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  IDOL:
    ADD_NEW_SCORE: 0.2
    APPLY_CLS_THRES: 0.05
    BATCH_INFER_LEN: 10
    CLASS_WEIGHT: 2.0
    CLIP_STRIDE: 1
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INFERENCE_FW: true
    INFERENCE_SELECT_THRES: 0.1
    INFERENCE_TW: true
    L1_WEIGHT: 5.0
    MASK_STRIDE: 4
    MASK_WEIGHT: 2.0
    MATCH_STRIDE: 4
    MEMORY_LEN: 3
    MERGE_ON_CPU: true
    MULTI_CLS_ON: true
    NHEADS: 8
    NMS_PRE: 0.5
    NUM_CLASSES: 40
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    REID_WEIGHT: 2.0
    SET_COST_BOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TEMPORAL_SCORE_TYPE: mean
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: IDOL
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: model_final.pth
OUTPUT_DIR: ./IDOL_YTVIS19_R50
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 12000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/28 17:37:52] detectron2 INFO: Full config saved to ./IDOL_YTVIS19_R50/config.yaml
[11/28 17:37:52] d2.utils.env INFO: Using a generated random seed 55911597
[11/28 17:37:56] d2.engine.defaults INFO: Model:
IDOL(
  (detr): CondInst_segm(
    (detr): DeformableDETR(
      (transformer): DeformableTransformer(
        (encoder): DeformableTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (decoder): DeformableTransformerDecoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerDecoderLayer(
              (cross_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (dropout2): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout4): Dropout(p=0.1, inplace=False)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (bbox_embed): ModuleList(
            (0-5): 6 x MLP(
              (layers): ModuleList(
                (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
                (2): Linear(in_features=256, out_features=4, bias=True)
              )
            )
          )
        )
        (reference_points): Linear(in_features=256, out_features=2, bias=True)
      )
      (class_embed): ModuleList(
        (0-5): 6 x Linear(in_features=256, out_features=40, bias=True)
      )
      (bbox_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (query_embed): Embedding(300, 512)
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (3): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (backbone): Joiner(
        (0): MaskedBackbone(
          (backbone): ResNet(
            (stem): BasicStem(
              (conv1): Conv2d(
                3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
            )
            (res2): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv1): Conv2d(
                  64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
            )
            (res3): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv1): Conv2d(
                  256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
            )
            (res4): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
                (conv1): Conv2d(
                  512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (4): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (5): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
            )
            (res5): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
                (conv1): Conv2d(
                  1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
            )
          )
        )
        (1): PositionEmbeddingSine()
      )
    )
    (controller): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=169, bias=True)
      )
    )
    (mask_head): MaskHeadSmallConv(
      (lay1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay2): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dcn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (reid_embed_head): MLP(
      (layers): ModuleList(
        (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[11/28 17:38:09] d2.data.common INFO: Serializing 2238 elements to byte tensors and concatenating them all ...
[11/28 17:38:09] d2.data.common INFO: Serialized dataset takes 150.26 MiB
[11/28 17:38:10] fvcore.common.checkpoint INFO: [Checkpointer] Loading from model_final.pth ...
[11/28 17:38:10] d2.engine.train_loop INFO: Starting Training from iteration 0
[11/28 17:38:39] d2.utils.events INFO:  eta: 2:53:55  iter: 19  total_loss: 9.092  loss_ce: 0.3337  loss_bbox: 0.1925  loss_giou: 0.1544  loss_mask: 0.03187  loss_dice: 0.3633  loss_reid: 2.083  loss_reid_aux: 0.0949  loss_ce_0: 0.3675  loss_bbox_0: 0.2831  loss_giou_0: 0.2257  loss_mask_0: 0.03341  loss_dice_0: 0.3729  loss_ce_1: 0.3413  loss_bbox_1: 0.2084  loss_giou_1: 0.1617  loss_mask_1: 0.03346  loss_dice_1: 0.3624  loss_ce_2: 0.3325  loss_bbox_2: 0.1921  loss_giou_2: 0.1515  loss_mask_2: 0.0327  loss_dice_2: 0.3525  loss_ce_3: 0.33  loss_bbox_3: 0.1931  loss_giou_3: 0.1531  loss_mask_3: 0.03226  loss_dice_3: 0.3541  loss_ce_4: 0.3269  loss_bbox_4: 0.1921  loss_giou_4: 0.1541  loss_mask_4: 0.0325  loss_dice_4: 0.3539  time: 0.8801  data_time: 0.5644  lr: 0.0001  max_mem: 17372M
[11/28 17:38:56] d2.utils.events INFO:  eta: 2:53:54  iter: 39  total_loss: 8.923  loss_ce: 0.2931  loss_bbox: 0.1821  loss_giou: 0.1514  loss_mask: 0.03606  loss_dice: 0.3693  loss_reid: 2.224  loss_reid_aux: 0.09131  loss_ce_0: 0.3537  loss_bbox_0: 0.251  loss_giou_0: 0.2174  loss_mask_0: 0.03615  loss_dice_0: 0.3979  loss_ce_1: 0.299  loss_bbox_1: 0.2029  loss_giou_1: 0.1609  loss_mask_1: 0.03517  loss_dice_1: 0.3803  loss_ce_2: 0.286  loss_bbox_2: 0.187  loss_giou_2: 0.1537  loss_mask_2: 0.03692  loss_dice_2: 0.3782  loss_ce_3: 0.2911  loss_bbox_3: 0.1893  loss_giou_3: 0.1523  loss_mask_3: 0.03457  loss_dice_3: 0.3737  loss_ce_4: 0.289  loss_bbox_4: 0.1844  loss_giou_4: 0.1505  loss_mask_4: 0.03532  loss_dice_4: 0.3671  time: 0.8683  data_time: 0.0329  lr: 0.0001  max_mem: 17552M
[11/28 17:39:13] d2.utils.events INFO:  eta: 2:52:12  iter: 59  total_loss: 8.533  loss_ce: 0.2724  loss_bbox: 0.1985  loss_giou: 0.1634  loss_mask: 0.03315  loss_dice: 0.3782  loss_reid: 1.805  loss_reid_aux: 0.0908  loss_ce_0: 0.3212  loss_bbox_0: 0.2958  loss_giou_0: 0.2379  loss_mask_0: 0.03472  loss_dice_0: 0.3823  loss_ce_1: 0.2882  loss_bbox_1: 0.2141  loss_giou_1: 0.1746  loss_mask_1: 0.0331  loss_dice_1: 0.3821  loss_ce_2: 0.2705  loss_bbox_2: 0.2043  loss_giou_2: 0.1677  loss_mask_2: 0.03324  loss_dice_2: 0.3793  loss_ce_3: 0.2678  loss_bbox_3: 0.2028  loss_giou_3: 0.1666  loss_mask_3: 0.03337  loss_dice_3: 0.3758  loss_ce_4: 0.2746  loss_bbox_4: 0.1987  loss_giou_4: 0.1638  loss_mask_4: 0.03311  loss_dice_4: 0.3736  time: 0.8636  data_time: 0.0254  lr: 0.0001  max_mem: 17552M
[11/28 17:39:30] d2.utils.events INFO:  eta: 2:51:47  iter: 79  total_loss: 8.727  loss_ce: 0.3014  loss_bbox: 0.2019  loss_giou: 0.1896  loss_mask: 0.03222  loss_dice: 0.3997  loss_reid: 2.224  loss_reid_aux: 0.08546  loss_ce_0: 0.3412  loss_bbox_0: 0.2856  loss_giou_0: 0.2494  loss_mask_0: 0.0348  loss_dice_0: 0.3912  loss_ce_1: 0.2961  loss_bbox_1: 0.2186  loss_giou_1: 0.2048  loss_mask_1: 0.03286  loss_dice_1: 0.3955  loss_ce_2: 0.2827  loss_bbox_2: 0.2102  loss_giou_2: 0.192  loss_mask_2: 0.03286  loss_dice_2: 0.3986  loss_ce_3: 0.2802  loss_bbox_3: 0.2079  loss_giou_3: 0.1927  loss_mask_3: 0.03384  loss_dice_3: 0.4001  loss_ce_4: 0.2935  loss_bbox_4: 0.2059  loss_giou_4: 0.1893  loss_mask_4: 0.03409  loss_dice_4: 0.3989  time: 0.8604  data_time: 0.0260  lr: 0.0001  max_mem: 17552M
[11/28 17:39:48] d2.utils.events INFO:  eta: 2:51:38  iter: 99  total_loss: 8.881  loss_ce: 0.3006  loss_bbox: 0.2098  loss_giou: 0.1647  loss_mask: 0.03771  loss_dice: 0.3781  loss_reid: 2.05  loss_reid_aux: 0.09427  loss_ce_0: 0.3667  loss_bbox_0: 0.2931  loss_giou_0: 0.2324  loss_mask_0: 0.03908  loss_dice_0: 0.3709  loss_ce_1: 0.3174  loss_bbox_1: 0.2292  loss_giou_1: 0.178  loss_mask_1: 0.03853  loss_dice_1: 0.3679  loss_ce_2: 0.3106  loss_bbox_2: 0.2173  loss_giou_2: 0.1633  loss_mask_2: 0.03796  loss_dice_2: 0.377  loss_ce_3: 0.2916  loss_bbox_3: 0.2171  loss_giou_3: 0.1659  loss_mask_3: 0.03821  loss_dice_3: 0.3753  loss_ce_4: 0.2981  loss_bbox_4: 0.2091  loss_giou_4: 0.1645  loss_mask_4: 0.03723  loss_dice_4: 0.3714  time: 0.8619  data_time: 0.0234  lr: 0.0001  max_mem: 17552M
[11/28 17:40:05] d2.utils.events INFO:  eta: 2:51:12  iter: 119  total_loss: 8.798  loss_ce: 0.2852  loss_bbox: 0.1918  loss_giou: 0.1593  loss_mask: 0.03488  loss_dice: 0.3899  loss_reid: 2.001  loss_reid_aux: 0.09214  loss_ce_0: 0.3452  loss_bbox_0: 0.2822  loss_giou_0: 0.2319  loss_mask_0: 0.03774  loss_dice_0: 0.3834  loss_ce_1: 0.2977  loss_bbox_1: 0.214  loss_giou_1: 0.1731  loss_mask_1: 0.03577  loss_dice_1: 0.3843  loss_ce_2: 0.2822  loss_bbox_2: 0.1975  loss_giou_2: 0.1621  loss_mask_2: 0.03629  loss_dice_2: 0.3895  loss_ce_3: 0.281  loss_bbox_3: 0.1953  loss_giou_3: 0.1641  loss_mask_3: 0.03609  loss_dice_3: 0.3913  loss_ce_4: 0.2826  loss_bbox_4: 0.1918  loss_giou_4: 0.1597  loss_mask_4: 0.03552  loss_dice_4: 0.3854  time: 0.8599  data_time: 0.0243  lr: 0.0001  max_mem: 17552M
[11/28 17:40:22] d2.utils.events INFO:  eta: 2:50:38  iter: 139  total_loss: 9.583  loss_ce: 0.3474  loss_bbox: 0.2021  loss_giou: 0.1652  loss_mask: 0.03705  loss_dice: 0.4006  loss_reid: 2.198  loss_reid_aux: 0.1081  loss_ce_0: 0.4044  loss_bbox_0: 0.301  loss_giou_0: 0.2414  loss_mask_0: 0.03752  loss_dice_0: 0.4051  loss_ce_1: 0.3394  loss_bbox_1: 0.216  loss_giou_1: 0.176  loss_mask_1: 0.03674  loss_dice_1: 0.4193  loss_ce_2: 0.3343  loss_bbox_2: 0.2054  loss_giou_2: 0.1632  loss_mask_2: 0.03623  loss_dice_2: 0.4045  loss_ce_3: 0.3356  loss_bbox_3: 0.206  loss_giou_3: 0.1645  loss_mask_3: 0.03507  loss_dice_3: 0.3965  loss_ce_4: 0.3373  loss_bbox_4: 0.2037  loss_giou_4: 0.1639  loss_mask_4: 0.03623  loss_dice_4: 0.3939  time: 0.8583  data_time: 0.0218  lr: 0.0001  max_mem: 17552M
[11/28 17:40:39] d2.utils.events INFO:  eta: 2:50:42  iter: 159  total_loss: 8.804  loss_ce: 0.2905  loss_bbox: 0.1919  loss_giou: 0.1676  loss_mask: 0.03032  loss_dice: 0.4217  loss_reid: 1.687  loss_reid_aux: 0.09588  loss_ce_0: 0.3373  loss_bbox_0: 0.2843  loss_giou_0: 0.2379  loss_mask_0: 0.03161  loss_dice_0: 0.4333  loss_ce_1: 0.2955  loss_bbox_1: 0.2086  loss_giou_1: 0.1809  loss_mask_1: 0.02982  loss_dice_1: 0.4246  loss_ce_2: 0.2786  loss_bbox_2: 0.1996  loss_giou_2: 0.1712  loss_mask_2: 0.0295  loss_dice_2: 0.4242  loss_ce_3: 0.2704  loss_bbox_3: 0.196  loss_giou_3: 0.1715  loss_mask_3: 0.031  loss_dice_3: 0.4311  loss_ce_4: 0.2751  loss_bbox_4: 0.191  loss_giou_4: 0.1675  loss_mask_4: 0.02987  loss_dice_4: 0.424  time: 0.8606  data_time: 0.0224  lr: 0.0001  max_mem: 17552M
[11/28 17:40:57] d2.utils.events INFO:  eta: 2:50:33  iter: 179  total_loss: 8.941  loss_ce: 0.3361  loss_bbox: 0.1967  loss_giou: 0.1734  loss_mask: 0.03436  loss_dice: 0.3989  loss_reid: 2.15  loss_reid_aux: 0.1092  loss_ce_0: 0.3764  loss_bbox_0: 0.2847  loss_giou_0: 0.2405  loss_mask_0: 0.03623  loss_dice_0: 0.3974  loss_ce_1: 0.3373  loss_bbox_1: 0.218  loss_giou_1: 0.1855  loss_mask_1: 0.03603  loss_dice_1: 0.4084  loss_ce_2: 0.3149  loss_bbox_2: 0.2091  loss_giou_2: 0.1761  loss_mask_2: 0.03738  loss_dice_2: 0.4052  loss_ce_3: 0.3113  loss_bbox_3: 0.1992  loss_giou_3: 0.1761  loss_mask_3: 0.03328  loss_dice_3: 0.406  loss_ce_4: 0.3178  loss_bbox_4: 0.1984  loss_giou_4: 0.1754  loss_mask_4: 0.03437  loss_dice_4: 0.4042  time: 0.8612  data_time: 0.0234  lr: 0.0001  max_mem: 17552M
[11/28 17:41:14] d2.utils.events INFO:  eta: 2:50:32  iter: 199  total_loss: 8.693  loss_ce: 0.3405  loss_bbox: 0.1911  loss_giou: 0.1695  loss_mask: 0.03149  loss_dice: 0.3691  loss_reid: 1.647  loss_reid_aux: 0.102  loss_ce_0: 0.357  loss_bbox_0: 0.2765  loss_giou_0: 0.2436  loss_mask_0: 0.03214  loss_dice_0: 0.3623  loss_ce_1: 0.3333  loss_bbox_1: 0.1996  loss_giou_1: 0.1812  loss_mask_1: 0.03219  loss_dice_1: 0.3714  loss_ce_2: 0.3429  loss_bbox_2: 0.1908  loss_giou_2: 0.1738  loss_mask_2: 0.03098  loss_dice_2: 0.3733  loss_ce_3: 0.3312  loss_bbox_3: 0.1914  loss_giou_3: 0.1725  loss_mask_3: 0.03216  loss_dice_3: 0.3718  loss_ce_4: 0.3326  loss_bbox_4: 0.1913  loss_giou_4: 0.1694  loss_mask_4: 0.03163  loss_dice_4: 0.3707  time: 0.8604  data_time: 0.0218  lr: 0.0001  max_mem: 17552M
[11/28 17:41:52] detectron2 INFO: Rank of current process: 0. World size: 4
[11/28 17:41:52] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]
numpy                   1.26.1
detectron2              0.6 @/vhome/wangyaoning/VNext/detectron2
Compiler                GCC 11.4
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          535.54.03
CUDA_HOME               /share/apps/cuda/12.2
Pillow                  10.1.0
torchvision             0.16.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 17:41:52] detectron2 INFO: Command line arguments: Namespace(config_file='projects/IDOL/configs/ytvis19_r50.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:59279', opts=[])
[11/28 17:41:52] detectron2 INFO: Contents of args.config_file=projects/IDOL/configs/ytvis19_r50.yaml:
MODEL:
  META_ARCHITECTURE: "IDOL"
  WEIGHTS: "model_final.pth"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: True
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  IDOL:
    NUM_CLASSES: 40
    MULTI_CLS_ON: True
DATASETS:
  TRAIN: ("ytvis_2019_train",)
  TEST: ("ytvis_2019_val",)
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (8000,)
  MAX_ITER: 12000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  CHECKPOINT_PERIOD: 1000
INPUT:
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE:  10
  # MIN_SIZE_TRAIN_SAMPLING : ["range", "choice", "range_by_clip", "choice_by_clip"]
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  # RANDOM_FLIP : ["none", "horizontal", "flip_by_clip"]. "horizontal" is set by default.
  RANDOM_FLIP: "flip_by_clip"
  # AUGMENTATIONS: []
  # MIN_SIZE_TRAIN: (360, 480)
  MIN_SIZE_TRAIN: (320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 4
VERSION: 2
OUTPUT_DIR: ./IDOL_YTVIS19_R50

[11/28 17:41:52] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - ytvis_2019_val
  TRAIN:
  - ytvis_2019_train
FIND_UNUSED_PARAMETERS: true
GLOBAL:
  HACK: 1.0
INPUT:
  AUGMENTATIONS: []
  COCO_PRETRAIN: false
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  MIN_SIZE_TRAIN:
  - 320
  - 352
  - 392
  - 416
  - 448
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  MIN_SIZE_TRAIN_SAMPLING: choice_by_clip
  PRETRAIN_SAME_CROP: false
  RANDOM_FLIP: flip_by_clip
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE: 10
  SAMPLING_FRAME_SHUFFLE: false
  SAMPLING_INTERVAL: 1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  IDOL:
    ADD_NEW_SCORE: 0.2
    APPLY_CLS_THRES: 0.05
    BATCH_INFER_LEN: 10
    CLASS_WEIGHT: 2.0
    CLIP_STRIDE: 1
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INFERENCE_FW: true
    INFERENCE_SELECT_THRES: 0.1
    INFERENCE_TW: true
    L1_WEIGHT: 5.0
    MASK_STRIDE: 4
    MASK_WEIGHT: 2.0
    MATCH_STRIDE: 4
    MEMORY_LEN: 3
    MERGE_ON_CPU: true
    MULTI_CLS_ON: true
    NHEADS: 8
    NMS_PRE: 0.5
    NUM_CLASSES: 40
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    REID_WEIGHT: 2.0
    SET_COST_BOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TEMPORAL_SCORE_TYPE: mean
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: IDOL
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: model_final.pth
OUTPUT_DIR: ./IDOL_YTVIS19_R50
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 12000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/28 17:41:52] detectron2 INFO: Full config saved to ./IDOL_YTVIS19_R50/config.yaml
[11/28 17:41:52] d2.utils.env INFO: Using a generated random seed 56409679
[11/28 17:41:56] d2.engine.defaults INFO: Model:
IDOL(
  (detr): CondInst_segm(
    (detr): DeformableDETR(
      (transformer): DeformableTransformer(
        (encoder): DeformableTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (decoder): DeformableTransformerDecoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerDecoderLayer(
              (cross_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (dropout2): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout4): Dropout(p=0.1, inplace=False)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (bbox_embed): ModuleList(
            (0-5): 6 x MLP(
              (layers): ModuleList(
                (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
                (2): Linear(in_features=256, out_features=4, bias=True)
              )
            )
          )
        )
        (reference_points): Linear(in_features=256, out_features=2, bias=True)
      )
      (class_embed): ModuleList(
        (0-5): 6 x Linear(in_features=256, out_features=40, bias=True)
      )
      (bbox_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (query_embed): Embedding(300, 512)
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (3): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (backbone): Joiner(
        (0): MaskedBackbone(
          (backbone): ResNet(
            (stem): BasicStem(
              (conv1): Conv2d(
                3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
            )
            (res2): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv1): Conv2d(
                  64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
            )
            (res3): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv1): Conv2d(
                  256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
            )
            (res4): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
                (conv1): Conv2d(
                  512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (4): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (5): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
            )
            (res5): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
                (conv1): Conv2d(
                  1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
            )
          )
        )
        (1): PositionEmbeddingSine()
      )
    )
    (controller): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=169, bias=True)
      )
    )
    (mask_head): MaskHeadSmallConv(
      (lay1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay2): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dcn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (reid_embed_head): MLP(
      (layers): ModuleList(
        (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[11/28 17:42:10] d2.data.common INFO: Serializing 2238 elements to byte tensors and concatenating them all ...
[11/28 17:42:10] d2.data.common INFO: Serialized dataset takes 150.26 MiB
[11/28 17:42:10] fvcore.common.checkpoint INFO: [Checkpointer] Loading from model_final.pth ...
[11/28 17:42:10] d2.engine.train_loop INFO: Starting Training from iteration 0
[11/28 17:44:20] detectron2 INFO: Rank of current process: 0. World size: 4
[11/28 17:44:21] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]
numpy                   1.26.1
detectron2              0.6 @/vhome/wangyaoning/VNext/detectron2
Compiler                GCC 11.4
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          535.54.03
CUDA_HOME               /share/apps/cuda/12.2
Pillow                  10.1.0
torchvision             0.16.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 17:44:21] detectron2 INFO: Command line arguments: Namespace(config_file='projects/IDOL/configs/ytvis19_r50.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:59279', opts=[])
[11/28 17:44:21] detectron2 INFO: Contents of args.config_file=projects/IDOL/configs/ytvis19_r50.yaml:
MODEL:
  META_ARCHITECTURE: "IDOL"
  WEIGHTS: "model_final.pth"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: True
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  IDOL:
    NUM_CLASSES: 40
    MULTI_CLS_ON: True
DATASETS:
  TRAIN: ("ytvis_2019_train",)
  TEST: ("ytvis_2019_val",)
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (8000,)
  MAX_ITER: 12000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  CHECKPOINT_PERIOD: 1000
INPUT:
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE:  10
  # MIN_SIZE_TRAIN_SAMPLING : ["range", "choice", "range_by_clip", "choice_by_clip"]
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  # RANDOM_FLIP : ["none", "horizontal", "flip_by_clip"]. "horizontal" is set by default.
  RANDOM_FLIP: "flip_by_clip"
  # AUGMENTATIONS: []
  # MIN_SIZE_TRAIN: (360, 480)
  MIN_SIZE_TRAIN: (320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 4
VERSION: 2
OUTPUT_DIR: ./IDOL_YTVIS19_R50

[11/28 17:44:21] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - ytvis_2019_val
  TRAIN:
  - ytvis_2019_train
FIND_UNUSED_PARAMETERS: true
GLOBAL:
  HACK: 1.0
INPUT:
  AUGMENTATIONS: []
  COCO_PRETRAIN: false
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  MIN_SIZE_TRAIN:
  - 320
  - 352
  - 392
  - 416
  - 448
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  MIN_SIZE_TRAIN_SAMPLING: choice_by_clip
  PRETRAIN_SAME_CROP: false
  RANDOM_FLIP: flip_by_clip
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE: 10
  SAMPLING_FRAME_SHUFFLE: false
  SAMPLING_INTERVAL: 1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  IDOL:
    ADD_NEW_SCORE: 0.2
    APPLY_CLS_THRES: 0.05
    BATCH_INFER_LEN: 10
    CLASS_WEIGHT: 2.0
    CLIP_STRIDE: 1
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INFERENCE_FW: true
    INFERENCE_SELECT_THRES: 0.1
    INFERENCE_TW: true
    L1_WEIGHT: 5.0
    MASK_STRIDE: 4
    MASK_WEIGHT: 2.0
    MATCH_STRIDE: 4
    MEMORY_LEN: 3
    MERGE_ON_CPU: true
    MULTI_CLS_ON: true
    NHEADS: 8
    NMS_PRE: 0.5
    NUM_CLASSES: 40
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    REID_WEIGHT: 2.0
    SET_COST_BOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TEMPORAL_SCORE_TYPE: mean
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: IDOL
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: model_final.pth
OUTPUT_DIR: ./IDOL_YTVIS19_R50
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 12000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/28 17:44:21] detectron2 INFO: Full config saved to ./IDOL_YTVIS19_R50/config.yaml
[11/28 17:44:21] d2.utils.env INFO: Using a generated random seed 25284081
[11/28 17:44:25] d2.engine.defaults INFO: Model:
IDOL(
  (detr): CondInst_segm(
    (detr): DeformableDETR(
      (transformer): DeformableTransformer(
        (encoder): DeformableTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (decoder): DeformableTransformerDecoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerDecoderLayer(
              (cross_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (dropout2): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout4): Dropout(p=0.1, inplace=False)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (bbox_embed): ModuleList(
            (0-5): 6 x MLP(
              (layers): ModuleList(
                (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
                (2): Linear(in_features=256, out_features=4, bias=True)
              )
            )
          )
        )
        (reference_points): Linear(in_features=256, out_features=2, bias=True)
      )
      (class_embed): ModuleList(
        (0-5): 6 x Linear(in_features=256, out_features=40, bias=True)
      )
      (bbox_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (query_embed): Embedding(300, 512)
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (3): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (backbone): Joiner(
        (0): MaskedBackbone(
          (backbone): ResNet(
            (stem): BasicStem(
              (conv1): Conv2d(
                3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
            )
            (res2): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv1): Conv2d(
                  64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
            )
            (res3): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv1): Conv2d(
                  256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
            )
            (res4): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
                (conv1): Conv2d(
                  512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (4): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (5): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
            )
            (res5): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
                (conv1): Conv2d(
                  1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
            )
          )
        )
        (1): PositionEmbeddingSine()
      )
    )
    (controller): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=169, bias=True)
      )
    )
    (mask_head): MaskHeadSmallConv(
      (lay1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay2): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dcn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (reid_embed_head): MLP(
      (layers): ModuleList(
        (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[11/28 17:44:39] d2.data.common INFO: Serializing 2238 elements to byte tensors and concatenating them all ...
[11/28 17:44:39] d2.data.common INFO: Serialized dataset takes 150.26 MiB
[11/28 17:44:40] fvcore.common.checkpoint INFO: [Checkpointer] Loading from model_final.pth ...
[11/28 17:44:40] d2.engine.train_loop INFO: Starting Training from iteration 0
[11/28 17:50:51] detectron2 INFO: Rank of current process: 0. World size: 4
[11/28 17:50:52] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]
numpy                   1.26.1
detectron2              0.6 @/vhome/wangyaoning/VNext/detectron2
Compiler                GCC 11.4
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          535.54.03
CUDA_HOME               /share/apps/cuda/12.2
Pillow                  10.1.0
torchvision             0.16.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 17:50:52] detectron2 INFO: Command line arguments: Namespace(config_file='projects/IDOL/configs/ytvis19_r50.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:59279', opts=[])
[11/28 17:50:52] detectron2 INFO: Contents of args.config_file=projects/IDOL/configs/ytvis19_r50.yaml:
MODEL:
  META_ARCHITECTURE: "IDOL"
  WEIGHTS: "model_final.pth"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: True
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  IDOL:
    NUM_CLASSES: 40
    MULTI_CLS_ON: True
DATASETS:
  TRAIN: ("ytvis_2019_train",)
  TEST: ("ytvis_2019_val",)
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (8000,)
  MAX_ITER: 12000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  CHECKPOINT_PERIOD: 1000
INPUT:
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE:  10
  # MIN_SIZE_TRAIN_SAMPLING : ["range", "choice", "range_by_clip", "choice_by_clip"]
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  # RANDOM_FLIP : ["none", "horizontal", "flip_by_clip"]. "horizontal" is set by default.
  RANDOM_FLIP: "flip_by_clip"
  # AUGMENTATIONS: []
  # MIN_SIZE_TRAIN: (360, 480)
  MIN_SIZE_TRAIN: (320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 4
VERSION: 2
OUTPUT_DIR: ./IDOL_YTVIS19_R50

[11/28 17:50:52] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - ytvis_2019_val
  TRAIN:
  - ytvis_2019_train
FIND_UNUSED_PARAMETERS: true
GLOBAL:
  HACK: 1.0
INPUT:
  AUGMENTATIONS: []
  COCO_PRETRAIN: false
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  MIN_SIZE_TRAIN:
  - 320
  - 352
  - 392
  - 416
  - 448
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  MIN_SIZE_TRAIN_SAMPLING: choice_by_clip
  PRETRAIN_SAME_CROP: false
  RANDOM_FLIP: flip_by_clip
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE: 10
  SAMPLING_FRAME_SHUFFLE: false
  SAMPLING_INTERVAL: 1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  IDOL:
    ADD_NEW_SCORE: 0.2
    APPLY_CLS_THRES: 0.05
    BATCH_INFER_LEN: 10
    CLASS_WEIGHT: 2.0
    CLIP_STRIDE: 1
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INFERENCE_FW: true
    INFERENCE_SELECT_THRES: 0.1
    INFERENCE_TW: true
    L1_WEIGHT: 5.0
    MASK_STRIDE: 4
    MASK_WEIGHT: 2.0
    MATCH_STRIDE: 4
    MEMORY_LEN: 3
    MERGE_ON_CPU: true
    MULTI_CLS_ON: true
    NHEADS: 8
    NMS_PRE: 0.5
    NUM_CLASSES: 40
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    REID_WEIGHT: 2.0
    SET_COST_BOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TEMPORAL_SCORE_TYPE: mean
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: IDOL
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: model_final.pth
OUTPUT_DIR: ./IDOL_YTVIS19_R50
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 12000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/28 17:50:52] detectron2 INFO: Full config saved to ./IDOL_YTVIS19_R50/config.yaml
[11/28 17:50:52] d2.utils.env INFO: Using a generated random seed 55720497
[11/28 17:50:55] d2.engine.defaults INFO: Model:
IDOL(
  (detr): CondInst_segm(
    (detr): DeformableDETR(
      (transformer): DeformableTransformer(
        (encoder): DeformableTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (decoder): DeformableTransformerDecoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerDecoderLayer(
              (cross_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (dropout2): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout4): Dropout(p=0.1, inplace=False)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (bbox_embed): ModuleList(
            (0-5): 6 x MLP(
              (layers): ModuleList(
                (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
                (2): Linear(in_features=256, out_features=4, bias=True)
              )
            )
          )
        )
        (reference_points): Linear(in_features=256, out_features=2, bias=True)
      )
      (class_embed): ModuleList(
        (0-5): 6 x Linear(in_features=256, out_features=40, bias=True)
      )
      (bbox_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (query_embed): Embedding(300, 512)
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (3): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (backbone): Joiner(
        (0): MaskedBackbone(
          (backbone): ResNet(
            (stem): BasicStem(
              (conv1): Conv2d(
                3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
            )
            (res2): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv1): Conv2d(
                  64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
            )
            (res3): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv1): Conv2d(
                  256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
            )
            (res4): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
                (conv1): Conv2d(
                  512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (4): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (5): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
            )
            (res5): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
                (conv1): Conv2d(
                  1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
            )
          )
        )
        (1): PositionEmbeddingSine()
      )
    )
    (controller): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=169, bias=True)
      )
    )
    (mask_head): MaskHeadSmallConv(
      (lay1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay2): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dcn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (reid_embed_head): MLP(
      (layers): ModuleList(
        (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[11/28 17:51:09] d2.data.common INFO: Serializing 2238 elements to byte tensors and concatenating them all ...
[11/28 17:51:09] d2.data.common INFO: Serialized dataset takes 150.26 MiB
[11/28 17:51:10] fvcore.common.checkpoint INFO: [Checkpointer] Loading from model_final.pth ...
[11/28 17:51:10] d2.engine.train_loop INFO: Starting Training from iteration 0
[11/28 17:51:23] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/vhome/wangyaoning/VNext/detectron2/engine/train_loop.py", line 153, in train
    self.run_step()
  File "/vhome/wangyaoning/VNext/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/vhome/wangyaoning/VNext/detectron2/engine/train_loop.py", line 279, in run_step
    loss_dict = self.model(data)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/idol.py", line 229, in forward
    output, loss_dict = self.detr(images, det_targets,ref_targets, self.criterion, train=True)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/models/segmentation_condInst.py", line 214, in forward
    contrast_items = select_pos_neg(inter_references_ref[-1], matched_ids, ref_targets,det_targets, self.reid_embed_head, hs[-1], hs_ref[-1], ref_cls)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/models/pos_neg_select.py", line 42, in select_pos_neg
    pos_idx = torch.stack(pos_idx)
TypeError: expected Tensor as element 0 in argument 0, but got NoneType
[11/28 17:51:23] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/28 17:51:23] d2.utils.events INFO:  iter: 1  total_loss: 5.197  loss_ce: 0.209  loss_bbox: 0.1578  loss_giou: 0.1212  loss_mask: 0.02291  loss_dice: 0.2853  loss_reid: 0.08656  loss_reid_aux: 0.06823  loss_ce_0: 0.2604  loss_bbox_0: 0.2427  loss_giou_0: 0.1838  loss_mask_0: 0.02246  loss_dice_0: 0.2905  loss_ce_1: 0.2395  loss_bbox_1: 0.1739  loss_giou_1: 0.1303  loss_mask_1: 0.0232  loss_dice_1: 0.2927  loss_ce_2: 0.2135  loss_bbox_2: 0.1653  loss_giou_2: 0.1248  loss_mask_2: 0.02325  loss_dice_2: 0.2858  loss_ce_3: 0.2005  loss_bbox_3: 0.1582  loss_giou_3: 0.1213  loss_mask_3: 0.02305  loss_dice_3: 0.2844  loss_ce_4: 0.1984  loss_bbox_4: 0.1577  loss_giou_4: 0.1212  loss_mask_4: 0.02281  loss_dice_4: 0.2869  data_time: 10.7671  lr: 0.0001  max_mem: 15430M
[11/28 18:08:52] detectron2 INFO: Rank of current process: 0. World size: 4
[11/28 18:08:52] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]
numpy                   1.26.1
detectron2              0.6 @/vhome/wangyaoning/VNext/detectron2
Compiler                GCC 11.4
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          535.54.03
CUDA_HOME               /share/apps/cuda/12.2
Pillow                  10.1.0
torchvision             0.16.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 18:08:52] detectron2 INFO: Command line arguments: Namespace(config_file='projects/IDOL/configs/ytvis19_r50.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:59279', opts=[])
[11/28 18:08:52] detectron2 INFO: Contents of args.config_file=projects/IDOL/configs/ytvis19_r50.yaml:
MODEL:
  META_ARCHITECTURE: "IDOL"
  WEIGHTS: "model_final.pth"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: True
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  IDOL:
    NUM_CLASSES: 40
    MULTI_CLS_ON: True
DATASETS:
  TRAIN: ("ytvis_2019_train",)
  TEST: ("ytvis_2019_val",)
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (8000,)
  MAX_ITER: 12000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  CHECKPOINT_PERIOD: 1000
INPUT:
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE:  10
  # MIN_SIZE_TRAIN_SAMPLING : ["range", "choice", "range_by_clip", "choice_by_clip"]
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  # RANDOM_FLIP : ["none", "horizontal", "flip_by_clip"]. "horizontal" is set by default.
  RANDOM_FLIP: "flip_by_clip"
  # AUGMENTATIONS: []
  # MIN_SIZE_TRAIN: (360, 480)
  MIN_SIZE_TRAIN: (320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 4
VERSION: 2
OUTPUT_DIR: ./IDOL_YTVIS19_R50

[11/28 18:08:52] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - ytvis_2019_val
  TRAIN:
  - ytvis_2019_train
FIND_UNUSED_PARAMETERS: true
GLOBAL:
  HACK: 1.0
INPUT:
  AUGMENTATIONS: []
  COCO_PRETRAIN: false
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  MIN_SIZE_TRAIN:
  - 320
  - 352
  - 392
  - 416
  - 448
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  MIN_SIZE_TRAIN_SAMPLING: choice_by_clip
  PRETRAIN_SAME_CROP: false
  RANDOM_FLIP: flip_by_clip
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE: 10
  SAMPLING_FRAME_SHUFFLE: false
  SAMPLING_INTERVAL: 1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  IDOL:
    ADD_NEW_SCORE: 0.2
    APPLY_CLS_THRES: 0.05
    BATCH_INFER_LEN: 10
    CLASS_WEIGHT: 2.0
    CLIP_STRIDE: 1
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INFERENCE_FW: true
    INFERENCE_SELECT_THRES: 0.1
    INFERENCE_TW: true
    L1_WEIGHT: 5.0
    MASK_STRIDE: 4
    MASK_WEIGHT: 2.0
    MATCH_STRIDE: 4
    MEMORY_LEN: 3
    MERGE_ON_CPU: true
    MULTI_CLS_ON: true
    NHEADS: 8
    NMS_PRE: 0.5
    NUM_CLASSES: 40
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    REID_WEIGHT: 2.0
    SET_COST_BOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TEMPORAL_SCORE_TYPE: mean
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: IDOL
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: model_final.pth
OUTPUT_DIR: ./IDOL_YTVIS19_R50
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 12000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/28 18:08:52] detectron2 INFO: Full config saved to ./IDOL_YTVIS19_R50/config.yaml
[11/28 18:08:52] d2.utils.env INFO: Using a generated random seed 56454690
[11/28 18:08:56] d2.engine.defaults INFO: Model:
IDOL(
  (detr): CondInst_segm(
    (detr): DeformableDETR(
      (transformer): DeformableTransformer(
        (encoder): DeformableTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (decoder): DeformableTransformerDecoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerDecoderLayer(
              (cross_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (dropout2): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout4): Dropout(p=0.1, inplace=False)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (bbox_embed): ModuleList(
            (0-5): 6 x MLP(
              (layers): ModuleList(
                (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
                (2): Linear(in_features=256, out_features=4, bias=True)
              )
            )
          )
        )
        (reference_points): Linear(in_features=256, out_features=2, bias=True)
      )
      (class_embed): ModuleList(
        (0-5): 6 x Linear(in_features=256, out_features=40, bias=True)
      )
      (bbox_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (query_embed): Embedding(300, 512)
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (3): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (backbone): Joiner(
        (0): MaskedBackbone(
          (backbone): ResNet(
            (stem): BasicStem(
              (conv1): Conv2d(
                3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
            )
            (res2): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv1): Conv2d(
                  64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
            )
            (res3): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv1): Conv2d(
                  256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
            )
            (res4): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
                (conv1): Conv2d(
                  512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (4): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (5): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
            )
            (res5): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
                (conv1): Conv2d(
                  1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
            )
          )
        )
        (1): PositionEmbeddingSine()
      )
    )
    (controller): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=169, bias=True)
      )
    )
    (mask_head): MaskHeadSmallConv(
      (lay1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay2): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dcn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (reid_embed_head): MLP(
      (layers): ModuleList(
        (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[11/28 18:09:10] d2.data.common INFO: Serializing 2238 elements to byte tensors and concatenating them all ...
[11/28 18:09:10] d2.data.common INFO: Serialized dataset takes 150.26 MiB
[11/28 18:09:10] fvcore.common.checkpoint INFO: [Checkpointer] Loading from model_final.pth ...
[11/28 18:09:11] d2.engine.train_loop INFO: Starting Training from iteration 0
[11/28 18:09:22] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/vhome/wangyaoning/VNext/detectron2/engine/train_loop.py", line 153, in train
    self.run_step()
  File "/vhome/wangyaoning/VNext/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/vhome/wangyaoning/VNext/detectron2/engine/train_loop.py", line 279, in run_step
    loss_dict = self.model(data)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/idol.py", line 229, in forward
    output, loss_dict = self.detr(images, det_targets,ref_targets, self.criterion, train=True)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/models/segmentation_condInst.py", line 190, in forward
    self.logger.log_id(f'hs_ref shape = {hs_ref.shape}, hs_ref[-1, pred_i] shape = {hs_ref[-1, pred_i].shape}', 1)
IndexError: The shape of the mask [300] at index 0 does not match the shape of the indexed tensor [4, 300, 256] at index 0
[11/28 18:09:22] d2.engine.hooks INFO: Total training time: 0:00:11 (0:00:00 on hooks)
[11/28 18:09:22] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 12839M
[11/28 18:11:52] detectron2 INFO: Rank of current process: 0. World size: 4
[11/28 18:11:52] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]
numpy                   1.26.1
detectron2              0.6 @/vhome/wangyaoning/VNext/detectron2
Compiler                GCC 11.4
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          535.54.03
CUDA_HOME               /share/apps/cuda/12.2
Pillow                  10.1.0
torchvision             0.16.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 18:11:52] detectron2 INFO: Command line arguments: Namespace(config_file='projects/IDOL/configs/ytvis19_r50.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:59279', opts=[])
[11/28 18:11:52] detectron2 INFO: Contents of args.config_file=projects/IDOL/configs/ytvis19_r50.yaml:
MODEL:
  META_ARCHITECTURE: "IDOL"
  WEIGHTS: "model_final.pth"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: True
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  IDOL:
    NUM_CLASSES: 40
    MULTI_CLS_ON: True
DATASETS:
  TRAIN: ("ytvis_2019_train",)
  TEST: ("ytvis_2019_val",)
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (8000,)
  MAX_ITER: 12000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  CHECKPOINT_PERIOD: 1000
INPUT:
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE:  10
  # MIN_SIZE_TRAIN_SAMPLING : ["range", "choice", "range_by_clip", "choice_by_clip"]
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  # RANDOM_FLIP : ["none", "horizontal", "flip_by_clip"]. "horizontal" is set by default.
  RANDOM_FLIP: "flip_by_clip"
  # AUGMENTATIONS: []
  # MIN_SIZE_TRAIN: (360, 480)
  MIN_SIZE_TRAIN: (320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 4
VERSION: 2
OUTPUT_DIR: ./IDOL_YTVIS19_R50

[11/28 18:11:52] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - ytvis_2019_val
  TRAIN:
  - ytvis_2019_train
FIND_UNUSED_PARAMETERS: true
GLOBAL:
  HACK: 1.0
INPUT:
  AUGMENTATIONS: []
  COCO_PRETRAIN: false
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  MIN_SIZE_TRAIN:
  - 320
  - 352
  - 392
  - 416
  - 448
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  MIN_SIZE_TRAIN_SAMPLING: choice_by_clip
  PRETRAIN_SAME_CROP: false
  RANDOM_FLIP: flip_by_clip
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE: 10
  SAMPLING_FRAME_SHUFFLE: false
  SAMPLING_INTERVAL: 1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  IDOL:
    ADD_NEW_SCORE: 0.2
    APPLY_CLS_THRES: 0.05
    BATCH_INFER_LEN: 10
    CLASS_WEIGHT: 2.0
    CLIP_STRIDE: 1
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INFERENCE_FW: true
    INFERENCE_SELECT_THRES: 0.1
    INFERENCE_TW: true
    L1_WEIGHT: 5.0
    MASK_STRIDE: 4
    MASK_WEIGHT: 2.0
    MATCH_STRIDE: 4
    MEMORY_LEN: 3
    MERGE_ON_CPU: true
    MULTI_CLS_ON: true
    NHEADS: 8
    NMS_PRE: 0.5
    NUM_CLASSES: 40
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    REID_WEIGHT: 2.0
    SET_COST_BOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TEMPORAL_SCORE_TYPE: mean
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: IDOL
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: model_final.pth
OUTPUT_DIR: ./IDOL_YTVIS19_R50
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 12000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/28 18:11:52] detectron2 INFO: Full config saved to ./IDOL_YTVIS19_R50/config.yaml
[11/28 18:11:52] d2.utils.env INFO: Using a generated random seed 56450922
[11/28 18:11:56] d2.engine.defaults INFO: Model:
IDOL(
  (detr): CondInst_segm(
    (detr): DeformableDETR(
      (transformer): DeformableTransformer(
        (encoder): DeformableTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (decoder): DeformableTransformerDecoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerDecoderLayer(
              (cross_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (dropout2): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout4): Dropout(p=0.1, inplace=False)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (bbox_embed): ModuleList(
            (0-5): 6 x MLP(
              (layers): ModuleList(
                (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
                (2): Linear(in_features=256, out_features=4, bias=True)
              )
            )
          )
        )
        (reference_points): Linear(in_features=256, out_features=2, bias=True)
      )
      (class_embed): ModuleList(
        (0-5): 6 x Linear(in_features=256, out_features=40, bias=True)
      )
      (bbox_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (query_embed): Embedding(300, 512)
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (3): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (backbone): Joiner(
        (0): MaskedBackbone(
          (backbone): ResNet(
            (stem): BasicStem(
              (conv1): Conv2d(
                3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
            )
            (res2): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv1): Conv2d(
                  64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
            )
            (res3): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv1): Conv2d(
                  256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
            )
            (res4): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
                (conv1): Conv2d(
                  512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (4): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (5): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
            )
            (res5): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
                (conv1): Conv2d(
                  1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
            )
          )
        )
        (1): PositionEmbeddingSine()
      )
    )
    (controller): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=169, bias=True)
      )
    )
    (mask_head): MaskHeadSmallConv(
      (lay1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay2): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dcn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (reid_embed_head): MLP(
      (layers): ModuleList(
        (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[11/28 18:12:09] d2.data.common INFO: Serializing 2238 elements to byte tensors and concatenating them all ...
[11/28 18:12:10] d2.data.common INFO: Serialized dataset takes 150.26 MiB
[11/28 18:12:10] fvcore.common.checkpoint INFO: [Checkpointer] Loading from model_final.pth ...
[11/28 18:12:10] d2.engine.train_loop INFO: Starting Training from iteration 0
[11/28 18:17:52] detectron2 INFO: Rank of current process: 0. World size: 4
[11/28 18:17:52] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]
numpy                   1.26.1
detectron2              0.6 @/vhome/wangyaoning/VNext/detectron2
Compiler                GCC 11.4
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          535.54.03
CUDA_HOME               /share/apps/cuda/12.2
Pillow                  10.1.0
torchvision             0.16.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 18:17:52] detectron2 INFO: Command line arguments: Namespace(config_file='projects/IDOL/configs/ytvis19_r50.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:59279', opts=[])
[11/28 18:17:52] detectron2 INFO: Contents of args.config_file=projects/IDOL/configs/ytvis19_r50.yaml:
MODEL:
  META_ARCHITECTURE: "IDOL"
  WEIGHTS: "model_final.pth"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: True
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  IDOL:
    NUM_CLASSES: 40
    MULTI_CLS_ON: True
DATASETS:
  TRAIN: ("ytvis_2019_train",)
  TEST: ("ytvis_2019_val",)
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (8000,)
  MAX_ITER: 12000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  CHECKPOINT_PERIOD: 1000
INPUT:
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE:  10
  # MIN_SIZE_TRAIN_SAMPLING : ["range", "choice", "range_by_clip", "choice_by_clip"]
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  # RANDOM_FLIP : ["none", "horizontal", "flip_by_clip"]. "horizontal" is set by default.
  RANDOM_FLIP: "flip_by_clip"
  # AUGMENTATIONS: []
  # MIN_SIZE_TRAIN: (360, 480)
  MIN_SIZE_TRAIN: (320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 4
VERSION: 2
OUTPUT_DIR: ./IDOL_YTVIS19_R50

[11/28 18:17:52] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - ytvis_2019_val
  TRAIN:
  - ytvis_2019_train
FIND_UNUSED_PARAMETERS: true
GLOBAL:
  HACK: 1.0
INPUT:
  AUGMENTATIONS: []
  COCO_PRETRAIN: false
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  MIN_SIZE_TRAIN:
  - 320
  - 352
  - 392
  - 416
  - 448
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  MIN_SIZE_TRAIN_SAMPLING: choice_by_clip
  PRETRAIN_SAME_CROP: false
  RANDOM_FLIP: flip_by_clip
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE: 10
  SAMPLING_FRAME_SHUFFLE: false
  SAMPLING_INTERVAL: 1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  IDOL:
    ADD_NEW_SCORE: 0.2
    APPLY_CLS_THRES: 0.05
    BATCH_INFER_LEN: 10
    CLASS_WEIGHT: 2.0
    CLIP_STRIDE: 1
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INFERENCE_FW: true
    INFERENCE_SELECT_THRES: 0.1
    INFERENCE_TW: true
    L1_WEIGHT: 5.0
    MASK_STRIDE: 4
    MASK_WEIGHT: 2.0
    MATCH_STRIDE: 4
    MEMORY_LEN: 3
    MERGE_ON_CPU: true
    MULTI_CLS_ON: true
    NHEADS: 8
    NMS_PRE: 0.5
    NUM_CLASSES: 40
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    REID_WEIGHT: 2.0
    SET_COST_BOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TEMPORAL_SCORE_TYPE: mean
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: IDOL
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: model_final.pth
OUTPUT_DIR: ./IDOL_YTVIS19_R50
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 12000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/28 18:17:52] detectron2 INFO: Full config saved to ./IDOL_YTVIS19_R50/config.yaml
[11/28 18:17:53] d2.utils.env INFO: Using a generated random seed 56607773
[11/28 18:17:56] d2.engine.defaults INFO: Model:
IDOL(
  (detr): CondInst_segm(
    (detr): DeformableDETR(
      (transformer): DeformableTransformer(
        (encoder): DeformableTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (decoder): DeformableTransformerDecoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerDecoderLayer(
              (cross_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (dropout2): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout4): Dropout(p=0.1, inplace=False)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (bbox_embed): ModuleList(
            (0-5): 6 x MLP(
              (layers): ModuleList(
                (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
                (2): Linear(in_features=256, out_features=4, bias=True)
              )
            )
          )
        )
        (reference_points): Linear(in_features=256, out_features=2, bias=True)
      )
      (class_embed): ModuleList(
        (0-5): 6 x Linear(in_features=256, out_features=40, bias=True)
      )
      (bbox_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (query_embed): Embedding(300, 512)
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (3): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (backbone): Joiner(
        (0): MaskedBackbone(
          (backbone): ResNet(
            (stem): BasicStem(
              (conv1): Conv2d(
                3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
            )
            (res2): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv1): Conv2d(
                  64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
            )
            (res3): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv1): Conv2d(
                  256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
            )
            (res4): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
                (conv1): Conv2d(
                  512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (4): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (5): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
            )
            (res5): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
                (conv1): Conv2d(
                  1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
            )
          )
        )
        (1): PositionEmbeddingSine()
      )
    )
    (controller): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=169, bias=True)
      )
    )
    (mask_head): MaskHeadSmallConv(
      (lay1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay2): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dcn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (reid_embed_head): MLP(
      (layers): ModuleList(
        (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[11/28 18:18:10] d2.data.common INFO: Serializing 2238 elements to byte tensors and concatenating them all ...
[11/28 18:18:11] d2.data.common INFO: Serialized dataset takes 150.26 MiB
[11/28 18:18:11] fvcore.common.checkpoint INFO: [Checkpointer] Loading from model_final.pth ...
[11/28 18:18:11] d2.engine.train_loop INFO: Starting Training from iteration 0
[11/28 18:18:23] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/vhome/wangyaoning/VNext/detectron2/engine/train_loop.py", line 153, in train
    self.run_step()
  File "/vhome/wangyaoning/VNext/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/vhome/wangyaoning/VNext/detectron2/engine/train_loop.py", line 279, in run_step
    loss_dict = self.model(data)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/idol.py", line 229, in forward
    output, loss_dict = self.detr(images, det_targets,ref_targets, self.criterion, train=True)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/models/segmentation_condInst.py", line 218, in forward
    contrast_items = select_pos_neg(inter_references_ref[-1], matched_ids, ref_targets,det_targets, self.reid_embed_head, hs[-1], hs_ref[-1], ref_cls)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/models/pos_neg_select.py", line 42, in select_pos_neg
    pos_idx = torch.stack(pos_idx)
TypeError: expected Tensor as element 1 in argument 0, but got NoneType
[11/28 18:18:23] d2.engine.hooks INFO: Total training time: 0:00:11 (0:00:00 on hooks)
[11/28 18:18:23] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 16152M
[11/28 18:35:22] detectron2 INFO: Rank of current process: 0. World size: 4
[11/28 18:35:23] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]
numpy                   1.26.1
detectron2              0.6 @/vhome/wangyaoning/VNext/detectron2
Compiler                GCC 11.4
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          535.54.03
CUDA_HOME               /share/apps/cuda/12.2
Pillow                  10.1.0
torchvision             0.16.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 18:35:23] detectron2 INFO: Command line arguments: Namespace(config_file='projects/IDOL/configs/ytvis19_r50.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:59279', opts=[])
[11/28 18:35:23] detectron2 INFO: Contents of args.config_file=projects/IDOL/configs/ytvis19_r50.yaml:
MODEL:
  META_ARCHITECTURE: "IDOL"
  WEIGHTS: "model_final.pth"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: True
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  IDOL:
    NUM_CLASSES: 40
    MULTI_CLS_ON: True
DATASETS:
  TRAIN: ("ytvis_2019_train",)
  TEST: ("ytvis_2019_val",)
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (8000,)
  MAX_ITER: 12000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  CHECKPOINT_PERIOD: 1000
INPUT:
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE:  10
  # MIN_SIZE_TRAIN_SAMPLING : ["range", "choice", "range_by_clip", "choice_by_clip"]
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  # RANDOM_FLIP : ["none", "horizontal", "flip_by_clip"]. "horizontal" is set by default.
  RANDOM_FLIP: "flip_by_clip"
  # AUGMENTATIONS: []
  # MIN_SIZE_TRAIN: (360, 480)
  MIN_SIZE_TRAIN: (320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 4
VERSION: 2
OUTPUT_DIR: ./IDOL_YTVIS19_R50

[11/28 18:35:23] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - ytvis_2019_val
  TRAIN:
  - ytvis_2019_train
FIND_UNUSED_PARAMETERS: true
GLOBAL:
  HACK: 1.0
INPUT:
  AUGMENTATIONS: []
  COCO_PRETRAIN: false
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  MIN_SIZE_TRAIN:
  - 320
  - 352
  - 392
  - 416
  - 448
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  MIN_SIZE_TRAIN_SAMPLING: choice_by_clip
  PRETRAIN_SAME_CROP: false
  RANDOM_FLIP: flip_by_clip
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE: 10
  SAMPLING_FRAME_SHUFFLE: false
  SAMPLING_INTERVAL: 1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  IDOL:
    ADD_NEW_SCORE: 0.2
    APPLY_CLS_THRES: 0.05
    BATCH_INFER_LEN: 10
    CLASS_WEIGHT: 2.0
    CLIP_STRIDE: 1
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INFERENCE_FW: true
    INFERENCE_SELECT_THRES: 0.1
    INFERENCE_TW: true
    L1_WEIGHT: 5.0
    MASK_STRIDE: 4
    MASK_WEIGHT: 2.0
    MATCH_STRIDE: 4
    MEMORY_LEN: 3
    MERGE_ON_CPU: true
    MULTI_CLS_ON: true
    NHEADS: 8
    NMS_PRE: 0.5
    NUM_CLASSES: 40
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    REID_WEIGHT: 2.0
    SET_COST_BOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TEMPORAL_SCORE_TYPE: mean
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: IDOL
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: model_final.pth
OUTPUT_DIR: ./IDOL_YTVIS19_R50
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 12000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/28 18:35:23] detectron2 INFO: Full config saved to ./IDOL_YTVIS19_R50/config.yaml
[11/28 18:35:23] d2.utils.env INFO: Using a generated random seed 26708765
[11/28 18:35:26] d2.engine.defaults INFO: Model:
IDOL(
  (detr): CondInst_segm(
    (detr): DeformableDETR(
      (transformer): DeformableTransformer(
        (encoder): DeformableTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (decoder): DeformableTransformerDecoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerDecoderLayer(
              (cross_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (dropout2): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout4): Dropout(p=0.1, inplace=False)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (bbox_embed): ModuleList(
            (0-5): 6 x MLP(
              (layers): ModuleList(
                (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
                (2): Linear(in_features=256, out_features=4, bias=True)
              )
            )
          )
        )
        (reference_points): Linear(in_features=256, out_features=2, bias=True)
      )
      (class_embed): ModuleList(
        (0-5): 6 x Linear(in_features=256, out_features=40, bias=True)
      )
      (bbox_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (query_embed): Embedding(300, 512)
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (3): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (backbone): Joiner(
        (0): MaskedBackbone(
          (backbone): ResNet(
            (stem): BasicStem(
              (conv1): Conv2d(
                3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
            )
            (res2): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv1): Conv2d(
                  64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
            )
            (res3): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv1): Conv2d(
                  256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
            )
            (res4): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
                (conv1): Conv2d(
                  512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (4): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (5): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
            )
            (res5): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
                (conv1): Conv2d(
                  1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
            )
          )
        )
        (1): PositionEmbeddingSine()
      )
    )
    (controller): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=169, bias=True)
      )
    )
    (mask_head): MaskHeadSmallConv(
      (lay1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay2): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dcn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (reid_embed_head): MLP(
      (layers): ModuleList(
        (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[11/28 18:35:40] d2.data.common INFO: Serializing 2238 elements to byte tensors and concatenating them all ...
[11/28 18:35:40] d2.data.common INFO: Serialized dataset takes 150.26 MiB
[11/28 18:35:40] fvcore.common.checkpoint INFO: [Checkpointer] Loading from model_final.pth ...
[11/28 18:35:41] d2.engine.train_loop INFO: Starting Training from iteration 0
[11/28 18:35:52] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/vhome/wangyaoning/VNext/detectron2/engine/train_loop.py", line 153, in train
    self.run_step()
  File "/vhome/wangyaoning/VNext/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/vhome/wangyaoning/VNext/detectron2/engine/train_loop.py", line 279, in run_step
    loss_dict = self.model(data)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/idol.py", line 229, in forward
    output, loss_dict = self.detr(images, det_targets,ref_targets, self.criterion, train=True)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/models/segmentation_condInst.py", line 199, in forward
    self.queue.enqueue(item)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'CondInst_segm' object has no attribute 'queue'
[11/28 18:35:52] d2.engine.hooks INFO: Total training time: 0:00:11 (0:00:00 on hooks)
[11/28 18:35:52] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 12884M
[11/28 18:37:20] detectron2 INFO: Rank of current process: 0. World size: 4
[11/28 18:37:21] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]
numpy                   1.26.1
detectron2              0.6 @/vhome/wangyaoning/VNext/detectron2
Compiler                GCC 11.4
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          535.54.03
CUDA_HOME               /share/apps/cuda/12.2
Pillow                  10.1.0
torchvision             0.16.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 18:37:21] detectron2 INFO: Command line arguments: Namespace(config_file='projects/IDOL/configs/ytvis19_r50.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:59279', opts=[])
[11/28 18:37:21] detectron2 INFO: Contents of args.config_file=projects/IDOL/configs/ytvis19_r50.yaml:
MODEL:
  META_ARCHITECTURE: "IDOL"
  WEIGHTS: "model_final.pth"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: True
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  IDOL:
    NUM_CLASSES: 40
    MULTI_CLS_ON: True
DATASETS:
  TRAIN: ("ytvis_2019_train",)
  TEST: ("ytvis_2019_val",)
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (8000,)
  MAX_ITER: 12000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  CHECKPOINT_PERIOD: 1000
INPUT:
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE:  10
  # MIN_SIZE_TRAIN_SAMPLING : ["range", "choice", "range_by_clip", "choice_by_clip"]
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  # RANDOM_FLIP : ["none", "horizontal", "flip_by_clip"]. "horizontal" is set by default.
  RANDOM_FLIP: "flip_by_clip"
  # AUGMENTATIONS: []
  # MIN_SIZE_TRAIN: (360, 480)
  MIN_SIZE_TRAIN: (320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 4
VERSION: 2
OUTPUT_DIR: ./IDOL_YTVIS19_R50

[11/28 18:37:21] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - ytvis_2019_val
  TRAIN:
  - ytvis_2019_train
FIND_UNUSED_PARAMETERS: true
GLOBAL:
  HACK: 1.0
INPUT:
  AUGMENTATIONS: []
  COCO_PRETRAIN: false
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  MIN_SIZE_TRAIN:
  - 320
  - 352
  - 392
  - 416
  - 448
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  MIN_SIZE_TRAIN_SAMPLING: choice_by_clip
  PRETRAIN_SAME_CROP: false
  RANDOM_FLIP: flip_by_clip
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE: 10
  SAMPLING_FRAME_SHUFFLE: false
  SAMPLING_INTERVAL: 1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  IDOL:
    ADD_NEW_SCORE: 0.2
    APPLY_CLS_THRES: 0.05
    BATCH_INFER_LEN: 10
    CLASS_WEIGHT: 2.0
    CLIP_STRIDE: 1
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INFERENCE_FW: true
    INFERENCE_SELECT_THRES: 0.1
    INFERENCE_TW: true
    L1_WEIGHT: 5.0
    MASK_STRIDE: 4
    MASK_WEIGHT: 2.0
    MATCH_STRIDE: 4
    MEMORY_LEN: 3
    MERGE_ON_CPU: true
    MULTI_CLS_ON: true
    NHEADS: 8
    NMS_PRE: 0.5
    NUM_CLASSES: 40
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    REID_WEIGHT: 2.0
    SET_COST_BOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TEMPORAL_SCORE_TYPE: mean
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: IDOL
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: model_final.pth
OUTPUT_DIR: ./IDOL_YTVIS19_R50
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 12000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/28 18:37:21] detectron2 INFO: Full config saved to ./IDOL_YTVIS19_R50/config.yaml
[11/28 18:37:21] d2.utils.env INFO: Using a generated random seed 24895388
[11/28 18:37:24] d2.engine.defaults INFO: Model:
IDOL(
  (detr): CondInst_segm(
    (detr): DeformableDETR(
      (transformer): DeformableTransformer(
        (encoder): DeformableTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (decoder): DeformableTransformerDecoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerDecoderLayer(
              (cross_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (dropout2): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout4): Dropout(p=0.1, inplace=False)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (bbox_embed): ModuleList(
            (0-5): 6 x MLP(
              (layers): ModuleList(
                (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
                (2): Linear(in_features=256, out_features=4, bias=True)
              )
            )
          )
        )
        (reference_points): Linear(in_features=256, out_features=2, bias=True)
      )
      (class_embed): ModuleList(
        (0-5): 6 x Linear(in_features=256, out_features=40, bias=True)
      )
      (bbox_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (query_embed): Embedding(300, 512)
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (3): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (backbone): Joiner(
        (0): MaskedBackbone(
          (backbone): ResNet(
            (stem): BasicStem(
              (conv1): Conv2d(
                3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
            )
            (res2): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv1): Conv2d(
                  64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
            )
            (res3): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv1): Conv2d(
                  256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
            )
            (res4): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
                (conv1): Conv2d(
                  512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (4): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (5): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
            )
            (res5): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
                (conv1): Conv2d(
                  1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
            )
          )
        )
        (1): PositionEmbeddingSine()
      )
    )
    (controller): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=169, bias=True)
      )
    )
    (mask_head): MaskHeadSmallConv(
      (lay1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay2): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dcn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (reid_embed_head): MLP(
      (layers): ModuleList(
        (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[11/28 18:37:38] d2.data.common INFO: Serializing 2238 elements to byte tensors and concatenating them all ...
[11/28 18:37:38] d2.data.common INFO: Serialized dataset takes 150.26 MiB
[11/28 18:37:38] fvcore.common.checkpoint INFO: [Checkpointer] Loading from model_final.pth ...
[11/28 18:37:38] d2.engine.train_loop INFO: Starting Training from iteration 0
[11/28 18:37:50] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/vhome/wangyaoning/VNext/detectron2/engine/train_loop.py", line 153, in train
    self.run_step()
  File "/vhome/wangyaoning/VNext/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/vhome/wangyaoning/VNext/detectron2/engine/train_loop.py", line 279, in run_step
    loss_dict = self.model(data)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/idol.py", line 229, in forward
    output, loss_dict = self.detr(images, det_targets,ref_targets, self.criterion, train=True)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/models/segmentation_condInst.py", line 228, in forward
    contrast_items = select_pos_neg(inter_references_ref[-1], matched_ids, ref_targets,det_targets, self.reid_embed_head, hs[-1], hs_ref[-1], ref_cls, self.queue)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'CondInst_segm' object has no attribute 'queue'
[11/28 18:37:50] d2.engine.hooks INFO: Total training time: 0:00:11 (0:00:00 on hooks)
[11/28 18:37:50] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 13537M
[11/28 18:40:23] detectron2 INFO: Rank of current process: 0. World size: 4
[11/28 18:40:24] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]
numpy                   1.26.1
detectron2              0.6 @/vhome/wangyaoning/VNext/detectron2
Compiler                GCC 11.4
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          535.54.03
CUDA_HOME               /share/apps/cuda/12.2
Pillow                  10.1.0
torchvision             0.16.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 18:40:24] detectron2 INFO: Command line arguments: Namespace(config_file='projects/IDOL/configs/ytvis19_r50.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:59279', opts=[])
[11/28 18:40:24] detectron2 INFO: Contents of args.config_file=projects/IDOL/configs/ytvis19_r50.yaml:
MODEL:
  META_ARCHITECTURE: "IDOL"
  WEIGHTS: "model_final.pth"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: True
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  IDOL:
    NUM_CLASSES: 40
    MULTI_CLS_ON: True
DATASETS:
  TRAIN: ("ytvis_2019_train",)
  TEST: ("ytvis_2019_val",)
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (8000,)
  MAX_ITER: 12000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  CHECKPOINT_PERIOD: 1000
INPUT:
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE:  10
  # MIN_SIZE_TRAIN_SAMPLING : ["range", "choice", "range_by_clip", "choice_by_clip"]
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  # RANDOM_FLIP : ["none", "horizontal", "flip_by_clip"]. "horizontal" is set by default.
  RANDOM_FLIP: "flip_by_clip"
  # AUGMENTATIONS: []
  # MIN_SIZE_TRAIN: (360, 480)
  MIN_SIZE_TRAIN: (320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 4
VERSION: 2
OUTPUT_DIR: ./IDOL_YTVIS19_R50

[11/28 18:40:24] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - ytvis_2019_val
  TRAIN:
  - ytvis_2019_train
FIND_UNUSED_PARAMETERS: true
GLOBAL:
  HACK: 1.0
INPUT:
  AUGMENTATIONS: []
  COCO_PRETRAIN: false
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  MIN_SIZE_TRAIN:
  - 320
  - 352
  - 392
  - 416
  - 448
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  MIN_SIZE_TRAIN_SAMPLING: choice_by_clip
  PRETRAIN_SAME_CROP: false
  RANDOM_FLIP: flip_by_clip
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE: 10
  SAMPLING_FRAME_SHUFFLE: false
  SAMPLING_INTERVAL: 1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  IDOL:
    ADD_NEW_SCORE: 0.2
    APPLY_CLS_THRES: 0.05
    BATCH_INFER_LEN: 10
    CLASS_WEIGHT: 2.0
    CLIP_STRIDE: 1
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INFERENCE_FW: true
    INFERENCE_SELECT_THRES: 0.1
    INFERENCE_TW: true
    L1_WEIGHT: 5.0
    MASK_STRIDE: 4
    MASK_WEIGHT: 2.0
    MATCH_STRIDE: 4
    MEMORY_LEN: 3
    MERGE_ON_CPU: true
    MULTI_CLS_ON: true
    NHEADS: 8
    NMS_PRE: 0.5
    NUM_CLASSES: 40
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    REID_WEIGHT: 2.0
    SET_COST_BOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TEMPORAL_SCORE_TYPE: mean
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: IDOL
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: model_final.pth
OUTPUT_DIR: ./IDOL_YTVIS19_R50
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 12000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/28 18:40:24] detectron2 INFO: Full config saved to ./IDOL_YTVIS19_R50/config.yaml
[11/28 18:40:24] d2.utils.env INFO: Using a generated random seed 27673252
[11/28 18:40:27] d2.engine.defaults INFO: Model:
IDOL(
  (detr): CondInst_segm(
    (detr): DeformableDETR(
      (transformer): DeformableTransformer(
        (encoder): DeformableTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (decoder): DeformableTransformerDecoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerDecoderLayer(
              (cross_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (dropout2): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout4): Dropout(p=0.1, inplace=False)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (bbox_embed): ModuleList(
            (0-5): 6 x MLP(
              (layers): ModuleList(
                (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
                (2): Linear(in_features=256, out_features=4, bias=True)
              )
            )
          )
        )
        (reference_points): Linear(in_features=256, out_features=2, bias=True)
      )
      (class_embed): ModuleList(
        (0-5): 6 x Linear(in_features=256, out_features=40, bias=True)
      )
      (bbox_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (query_embed): Embedding(300, 512)
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (3): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (backbone): Joiner(
        (0): MaskedBackbone(
          (backbone): ResNet(
            (stem): BasicStem(
              (conv1): Conv2d(
                3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
            )
            (res2): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv1): Conv2d(
                  64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
            )
            (res3): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv1): Conv2d(
                  256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
            )
            (res4): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
                (conv1): Conv2d(
                  512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (4): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (5): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
            )
            (res5): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
                (conv1): Conv2d(
                  1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
            )
          )
        )
        (1): PositionEmbeddingSine()
      )
    )
    (controller): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=169, bias=True)
      )
    )
    (mask_head): MaskHeadSmallConv(
      (lay1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay2): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dcn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (reid_embed_head): MLP(
      (layers): ModuleList(
        (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[11/28 18:40:41] d2.data.common INFO: Serializing 2238 elements to byte tensors and concatenating them all ...
[11/28 18:40:41] d2.data.common INFO: Serialized dataset takes 150.26 MiB
[11/28 18:40:42] fvcore.common.checkpoint INFO: [Checkpointer] Loading from model_final.pth ...
[11/28 18:40:42] d2.engine.train_loop INFO: Starting Training from iteration 0
[11/28 18:40:54] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/vhome/wangyaoning/VNext/detectron2/engine/train_loop.py", line 153, in train
    self.run_step()
  File "/vhome/wangyaoning/VNext/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/vhome/wangyaoning/VNext/detectron2/engine/train_loop.py", line 279, in run_step
    loss_dict = self.model(data)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/idol.py", line 229, in forward
    output, loss_dict = self.detr(images, det_targets,ref_targets, self.criterion, train=True)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/models/segmentation_condInst.py", line 228, in forward
    contrast_items = select_pos_neg(inter_references_ref[-1], matched_ids, ref_targets,det_targets, self.reid_embed_head, hs[-1], hs_ref[-1], ref_cls, self.object_queue)
  File "/vhome/wangyaoning/VNext/projects/IDOL/idol/models/pos_neg_select.py", line 42, in select_pos_neg
    pos_idx = torch.stack(pos_idx)
TypeError: expected Tensor as element 0 in argument 0, but got NoneType
[11/28 18:40:54] d2.engine.hooks INFO: Total training time: 0:00:11 (0:00:00 on hooks)
[11/28 18:40:54] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 16108M
[11/28 18:53:52] detectron2 INFO: Rank of current process: 0. World size: 4
[11/28 18:53:52] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]
numpy                   1.26.1
detectron2              0.6 @/vhome/wangyaoning/VNext/detectron2
Compiler                GCC 11.4
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          535.54.03
CUDA_HOME               /share/apps/cuda/12.2
Pillow                  10.1.0
torchvision             0.16.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 18:53:52] detectron2 INFO: Command line arguments: Namespace(config_file='projects/IDOL/configs/ytvis19_r50.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:59279', opts=[])
[11/28 18:53:52] detectron2 INFO: Contents of args.config_file=projects/IDOL/configs/ytvis19_r50.yaml:
MODEL:
  META_ARCHITECTURE: "IDOL"
  WEIGHTS: "model_final.pth"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: True
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  IDOL:
    NUM_CLASSES: 40
    MULTI_CLS_ON: True
DATASETS:
  TRAIN: ("ytvis_2019_train",)
  TEST: ("ytvis_2019_val",)
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (8000,)
  MAX_ITER: 12000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  CHECKPOINT_PERIOD: 1000
INPUT:
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE:  10
  # MIN_SIZE_TRAIN_SAMPLING : ["range", "choice", "range_by_clip", "choice_by_clip"]
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  # RANDOM_FLIP : ["none", "horizontal", "flip_by_clip"]. "horizontal" is set by default.
  RANDOM_FLIP: "flip_by_clip"
  # AUGMENTATIONS: []
  # MIN_SIZE_TRAIN: (360, 480)
  MIN_SIZE_TRAIN: (320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 4
VERSION: 2
OUTPUT_DIR: ./IDOL_YTVIS19_R50

[11/28 18:53:52] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - ytvis_2019_val
  TRAIN:
  - ytvis_2019_train
FIND_UNUSED_PARAMETERS: true
GLOBAL:
  HACK: 1.0
INPUT:
  AUGMENTATIONS: []
  COCO_PRETRAIN: false
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  MIN_SIZE_TRAIN:
  - 320
  - 352
  - 392
  - 416
  - 448
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  MIN_SIZE_TRAIN_SAMPLING: choice_by_clip
  PRETRAIN_SAME_CROP: false
  RANDOM_FLIP: flip_by_clip
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE: 10
  SAMPLING_FRAME_SHUFFLE: false
  SAMPLING_INTERVAL: 1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  IDOL:
    ADD_NEW_SCORE: 0.2
    APPLY_CLS_THRES: 0.05
    BATCH_INFER_LEN: 10
    CLASS_WEIGHT: 2.0
    CLIP_STRIDE: 1
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INFERENCE_FW: true
    INFERENCE_SELECT_THRES: 0.1
    INFERENCE_TW: true
    L1_WEIGHT: 5.0
    MASK_STRIDE: 4
    MASK_WEIGHT: 2.0
    MATCH_STRIDE: 4
    MEMORY_LEN: 3
    MERGE_ON_CPU: true
    MULTI_CLS_ON: true
    NHEADS: 8
    NMS_PRE: 0.5
    NUM_CLASSES: 40
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    REID_WEIGHT: 2.0
    SET_COST_BOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TEMPORAL_SCORE_TYPE: mean
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: IDOL
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: model_final.pth
OUTPUT_DIR: ./IDOL_YTVIS19_R50
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 12000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/28 18:53:52] detectron2 INFO: Full config saved to ./IDOL_YTVIS19_R50/config.yaml
[11/28 18:53:52] d2.utils.env INFO: Using a generated random seed 56313768
[11/28 18:53:56] d2.engine.defaults INFO: Model:
IDOL(
  (detr): CondInst_segm(
    (detr): DeformableDETR(
      (transformer): DeformableTransformer(
        (encoder): DeformableTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (decoder): DeformableTransformerDecoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerDecoderLayer(
              (cross_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (dropout2): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout4): Dropout(p=0.1, inplace=False)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (bbox_embed): ModuleList(
            (0-5): 6 x MLP(
              (layers): ModuleList(
                (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
                (2): Linear(in_features=256, out_features=4, bias=True)
              )
            )
          )
        )
        (reference_points): Linear(in_features=256, out_features=2, bias=True)
      )
      (class_embed): ModuleList(
        (0-5): 6 x Linear(in_features=256, out_features=40, bias=True)
      )
      (bbox_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (query_embed): Embedding(300, 512)
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (3): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (backbone): Joiner(
        (0): MaskedBackbone(
          (backbone): ResNet(
            (stem): BasicStem(
              (conv1): Conv2d(
                3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
            )
            (res2): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv1): Conv2d(
                  64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
            )
            (res3): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv1): Conv2d(
                  256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
            )
            (res4): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
                (conv1): Conv2d(
                  512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (4): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (5): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
            )
            (res5): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
                (conv1): Conv2d(
                  1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
            )
          )
        )
        (1): PositionEmbeddingSine()
      )
    )
    (controller): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=169, bias=True)
      )
    )
    (mask_head): MaskHeadSmallConv(
      (lay1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay2): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dcn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (reid_embed_head): MLP(
      (layers): ModuleList(
        (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[11/28 18:54:10] d2.data.common INFO: Serializing 2238 elements to byte tensors and concatenating them all ...
[11/28 18:54:10] d2.data.common INFO: Serialized dataset takes 150.26 MiB
[11/28 18:54:11] fvcore.common.checkpoint INFO: [Checkpointer] Loading from model_final.pth ...
[11/28 18:54:11] d2.engine.train_loop INFO: Starting Training from iteration 0
[11/28 18:56:21] detectron2 INFO: Rank of current process: 0. World size: 4
[11/28 18:56:22] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]
numpy                   1.26.1
detectron2              0.6 @/vhome/wangyaoning/VNext/detectron2
Compiler                GCC 11.4
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          535.54.03
CUDA_HOME               /share/apps/cuda/12.2
Pillow                  10.1.0
torchvision             0.16.0+cu121 @/vhome/wangyaoning/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 18:56:22] detectron2 INFO: Command line arguments: Namespace(config_file='projects/IDOL/configs/ytvis19_r50.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:59279', opts=[])
[11/28 18:56:22] detectron2 INFO: Contents of args.config_file=projects/IDOL/configs/ytvis19_r50.yaml:
MODEL:
  META_ARCHITECTURE: "IDOL"
  WEIGHTS: "model_final.pth"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: True
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  IDOL:
    NUM_CLASSES: 40
    MULTI_CLS_ON: True
DATASETS:
  TRAIN: ("ytvis_2019_train",)
  TEST: ("ytvis_2019_val",)
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (8000,)
  MAX_ITER: 12000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  CHECKPOINT_PERIOD: 1000
INPUT:
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE:  10
  # MIN_SIZE_TRAIN_SAMPLING : ["range", "choice", "range_by_clip", "choice_by_clip"]
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  # RANDOM_FLIP : ["none", "horizontal", "flip_by_clip"]. "horizontal" is set by default.
  RANDOM_FLIP: "flip_by_clip"
  # AUGMENTATIONS: []
  # MIN_SIZE_TRAIN: (360, 480)
  MIN_SIZE_TRAIN: (320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 4
VERSION: 2
OUTPUT_DIR: ./IDOL_YTVIS19_R50

[11/28 18:56:22] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - ytvis_2019_val
  TRAIN:
  - ytvis_2019_train
FIND_UNUSED_PARAMETERS: true
GLOBAL:
  HACK: 1.0
INPUT:
  AUGMENTATIONS: []
  COCO_PRETRAIN: false
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  MIN_SIZE_TRAIN:
  - 320
  - 352
  - 392
  - 416
  - 448
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  MIN_SIZE_TRAIN_SAMPLING: choice_by_clip
  PRETRAIN_SAME_CROP: false
  RANDOM_FLIP: flip_by_clip
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE: 10
  SAMPLING_FRAME_SHUFFLE: false
  SAMPLING_INTERVAL: 1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  IDOL:
    ADD_NEW_SCORE: 0.2
    APPLY_CLS_THRES: 0.05
    BATCH_INFER_LEN: 10
    CLASS_WEIGHT: 2.0
    CLIP_STRIDE: 1
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INFERENCE_FW: true
    INFERENCE_SELECT_THRES: 0.1
    INFERENCE_TW: true
    L1_WEIGHT: 5.0
    MASK_STRIDE: 4
    MASK_WEIGHT: 2.0
    MATCH_STRIDE: 4
    MEMORY_LEN: 3
    MERGE_ON_CPU: true
    MULTI_CLS_ON: true
    NHEADS: 8
    NMS_PRE: 0.5
    NUM_CLASSES: 40
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    REID_WEIGHT: 2.0
    SET_COST_BOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TEMPORAL_SCORE_TYPE: mean
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: IDOL
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: model_final.pth
OUTPUT_DIR: ./IDOL_YTVIS19_R50
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 12000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/28 18:56:22] detectron2 INFO: Full config saved to ./IDOL_YTVIS19_R50/config.yaml
[11/28 18:56:22] d2.utils.env INFO: Using a generated random seed 26190375
[11/28 18:56:26] d2.engine.defaults INFO: Model:
IDOL(
  (detr): CondInst_segm(
    (detr): DeformableDETR(
      (transformer): DeformableTransformer(
        (encoder): DeformableTransformerEncoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (decoder): DeformableTransformerDecoder(
          (layers): ModuleList(
            (0-5): 6 x DeformableTransformerDecoderLayer(
              (cross_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.1, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (dropout2): Dropout(p=0.1, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout3): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout4): Dropout(p=0.1, inplace=False)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (bbox_embed): ModuleList(
            (0-5): 6 x MLP(
              (layers): ModuleList(
                (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
                (2): Linear(in_features=256, out_features=4, bias=True)
              )
            )
          )
        )
        (reference_points): Linear(in_features=256, out_features=2, bias=True)
      )
      (class_embed): ModuleList(
        (0-5): 6 x Linear(in_features=256, out_features=40, bias=True)
      )
      (bbox_embed): ModuleList(
        (0-5): 6 x MLP(
          (layers): ModuleList(
            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
      (query_embed): Embedding(300, 512)
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (3): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (backbone): Joiner(
        (0): MaskedBackbone(
          (backbone): ResNet(
            (stem): BasicStem(
              (conv1): Conv2d(
                3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
            )
            (res2): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv1): Conv2d(
                  64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv2): Conv2d(
                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
                )
                (conv3): Conv2d(
                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
              )
            )
            (res3): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv1): Conv2d(
                  256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv2): Conv2d(
                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
                )
                (conv3): Conv2d(
                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
              )
            )
            (res4): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
                (conv1): Conv2d(
                  512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (3): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (4): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
              (5): BottleneckBlock(
                (conv1): Conv2d(
                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv2): Conv2d(
                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
                )
                (conv3): Conv2d(
                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
                )
              )
            )
            (res5): Sequential(
              (0): BottleneckBlock(
                (shortcut): Conv2d(
                  1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
                (conv1): Conv2d(
                  1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (1): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
              (2): BottleneckBlock(
                (conv1): Conv2d(
                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv2): Conv2d(
                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
                )
                (conv3): Conv2d(
                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
                )
              )
            )
          )
        )
        (1): PositionEmbeddingSine()
      )
    )
    (controller): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=169, bias=True)
      )
    )
    (mask_head): MaskHeadSmallConv(
      (lay1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay2): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (lay4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dcn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (reid_embed_head): MLP(
      (layers): ModuleList(
        (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[11/28 18:56:40] d2.data.common INFO: Serializing 2238 elements to byte tensors and concatenating them all ...
[11/28 18:56:40] d2.data.common INFO: Serialized dataset takes 150.26 MiB
[11/28 18:56:41] fvcore.common.checkpoint INFO: [Checkpointer] Loading from model_final.pth ...
[11/28 18:56:41] d2.engine.train_loop INFO: Starting Training from iteration 0
[11/28 18:57:10] d2.utils.events INFO:  eta: 2:53:14  iter: 19  total_loss: 8.947  loss_ce: 0.2624  loss_bbox: 0.1971  loss_giou: 0.1668  loss_mask: 0.03392  loss_dice: 0.4086  loss_reid: 2.245  loss_reid_aux: 0.08695  loss_ce_0: 0.3105  loss_bbox_0: 0.2915  loss_giou_0: 0.2338  loss_mask_0: 0.03286  loss_dice_0: 0.4004  loss_ce_1: 0.2716  loss_bbox_1: 0.208  loss_giou_1: 0.1765  loss_mask_1: 0.03548  loss_dice_1: 0.4057  loss_ce_2: 0.2655  loss_bbox_2: 0.2043  loss_giou_2: 0.1703  loss_mask_2: 0.03409  loss_dice_2: 0.4059  loss_ce_3: 0.2621  loss_bbox_3: 0.2023  loss_giou_3: 0.1692  loss_mask_3: 0.03438  loss_dice_3: 0.3991  loss_ce_4: 0.2604  loss_bbox_4: 0.2011  loss_giou_4: 0.1681  loss_mask_4: 0.03419  loss_dice_4: 0.4027  time: 0.8643  data_time: 0.5624  lr: 0.0001  max_mem: 16889M
[11/28 18:57:27] d2.utils.events INFO:  eta: 2:52:34  iter: 39  total_loss: 8.406  loss_ce: 0.2785  loss_bbox: 0.1754  loss_giou: 0.1619  loss_mask: 0.0338  loss_dice: 0.3889  loss_reid: 1.382  loss_reid_aux: 0.08377  loss_ce_0: 0.3441  loss_bbox_0: 0.2551  loss_giou_0: 0.2265  loss_mask_0: 0.03584  loss_dice_0: 0.4085  loss_ce_1: 0.2949  loss_bbox_1: 0.1951  loss_giou_1: 0.1701  loss_mask_1: 0.03361  loss_dice_1: 0.4142  loss_ce_2: 0.2709  loss_bbox_2: 0.1826  loss_giou_2: 0.1634  loss_mask_2: 0.03165  loss_dice_2: 0.394  loss_ce_3: 0.272  loss_bbox_3: 0.1772  loss_giou_3: 0.1649  loss_mask_3: 0.03301  loss_dice_3: 0.3906  loss_ce_4: 0.2709  loss_bbox_4: 0.176  loss_giou_4: 0.1635  loss_mask_4: 0.03301  loss_dice_4: 0.3888  time: 0.8648  data_time: 0.0243  lr: 0.0001  max_mem: 16949M
[11/28 18:57:44] d2.utils.events INFO:  eta: 2:51:21  iter: 59  total_loss: 9.644  loss_ce: 0.2916  loss_bbox: 0.2385  loss_giou: 0.1681  loss_mask: 0.03934  loss_dice: 0.4009  loss_reid: 2.501  loss_reid_aux: 0.09852  loss_ce_0: 0.3261  loss_bbox_0: 0.3131  loss_giou_0: 0.234  loss_mask_0: 0.03979  loss_dice_0: 0.3915  loss_ce_1: 0.2891  loss_bbox_1: 0.2428  loss_giou_1: 0.1771  loss_mask_1: 0.04019  loss_dice_1: 0.3965  loss_ce_2: 0.2885  loss_bbox_2: 0.233  loss_giou_2: 0.1712  loss_mask_2: 0.03917  loss_dice_2: 0.3924  loss_ce_3: 0.2725  loss_bbox_3: 0.235  loss_giou_3: 0.1705  loss_mask_3: 0.03995  loss_dice_3: 0.4012  loss_ce_4: 0.2786  loss_bbox_4: 0.2362  loss_giou_4: 0.1698  loss_mask_4: 0.03929  loss_dice_4: 0.3963  time: 0.8596  data_time: 0.0287  lr: 0.0001  max_mem: 17143M
[11/28 18:58:01] d2.utils.events INFO:  eta: 2:51:04  iter: 79  total_loss: 8.689  loss_ce: 0.3029  loss_bbox: 0.21  loss_giou: 0.1589  loss_mask: 0.03278  loss_dice: 0.3732  loss_reid: 2.094  loss_reid_aux: 0.1055  loss_ce_0: 0.3537  loss_bbox_0: 0.3052  loss_giou_0: 0.2297  loss_mask_0: 0.03315  loss_dice_0: 0.3717  loss_ce_1: 0.3189  loss_bbox_1: 0.2288  loss_giou_1: 0.1686  loss_mask_1: 0.03222  loss_dice_1: 0.3633  loss_ce_2: 0.2869  loss_bbox_2: 0.2158  loss_giou_2: 0.1587  loss_mask_2: 0.03254  loss_dice_2: 0.3671  loss_ce_3: 0.2953  loss_bbox_3: 0.2135  loss_giou_3: 0.1578  loss_mask_3: 0.03344  loss_dice_3: 0.3717  loss_ce_4: 0.2987  loss_bbox_4: 0.2118  loss_giou_4: 0.1577  loss_mask_4: 0.03247  loss_dice_4: 0.3733  time: 0.8573  data_time: 0.0223  lr: 0.0001  max_mem: 17332M
[11/28 18:58:18] d2.utils.events INFO:  eta: 2:50:24  iter: 99  total_loss: 8.905  loss_ce: 0.3011  loss_bbox: 0.1849  loss_giou: 0.1555  loss_mask: 0.03339  loss_dice: 0.3635  loss_reid: 2.067  loss_reid_aux: 0.09436  loss_ce_0: 0.3303  loss_bbox_0: 0.2767  loss_giou_0: 0.2367  loss_mask_0: 0.03529  loss_dice_0: 0.3794  loss_ce_1: 0.2887  loss_bbox_1: 0.2024  loss_giou_1: 0.1698  loss_mask_1: 0.03252  loss_dice_1: 0.3622  loss_ce_2: 0.2914  loss_bbox_2: 0.195  loss_giou_2: 0.1586  loss_mask_2: 0.03283  loss_dice_2: 0.3757  loss_ce_3: 0.2868  loss_bbox_3: 0.1854  loss_giou_3: 0.1572  loss_mask_3: 0.03124  loss_dice_3: 0.3677  loss_ce_4: 0.2876  loss_bbox_4: 0.1856  loss_giou_4: 0.1564  loss_mask_4: 0.03258  loss_dice_4: 0.3663  time: 0.8548  data_time: 0.0217  lr: 0.0001  max_mem: 17332M
[11/28 18:58:35] d2.utils.events INFO:  eta: 2:50:12  iter: 119  total_loss: 8.349  loss_ce: 0.3014  loss_bbox: 0.2109  loss_giou: 0.1569  loss_mask: 0.03631  loss_dice: 0.3714  loss_reid: 1.534  loss_reid_aux: 0.07814  loss_ce_0: 0.3439  loss_bbox_0: 0.2873  loss_giou_0: 0.2329  loss_mask_0: 0.03781  loss_dice_0: 0.3954  loss_ce_1: 0.2959  loss_bbox_1: 0.219  loss_giou_1: 0.1697  loss_mask_1: 0.03793  loss_dice_1: 0.3718  loss_ce_2: 0.2881  loss_bbox_2: 0.2085  loss_giou_2: 0.1626  loss_mask_2: 0.03631  loss_dice_2: 0.3648  loss_ce_3: 0.2816  loss_bbox_3: 0.2111  loss_giou_3: 0.1575  loss_mask_3: 0.03625  loss_dice_3: 0.3689  loss_ce_4: 0.2855  loss_bbox_4: 0.2113  loss_giou_4: 0.1562  loss_mask_4: 0.03567  loss_dice_4: 0.3703  time: 0.8550  data_time: 0.0246  lr: 0.0001  max_mem: 17332M
